<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>AI 的历史，现状与发展 &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="AI发展驱动力(待更)" href="02drive.html" />
    <link rel="prev" title="=== 一、AI系统概述 ===" href="README.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="README.html">=== 一、AI系统概述 ===</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">AI 的历史，现状与发展</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/010system/01present.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="README.html">=== 一、AI系统概述 ===</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">AI 的历史，现状与发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="02drive.html">AI发展驱动力(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="03architecture.html">AI系统全栈架构(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="04sample.html">AI系统样例(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05principle.html">AI系统原则(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="06foundation.html">大模型的到来(待更)</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../020Hardware/README.html">=== 二、AI芯片体系结构 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021HW_Foundation/README.html">1. AI 计算体系概述</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/05.matrix.html">1.5. 核心计算之矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/06.bit_width.html">1.6. 计算之比特位宽</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022HW_ChipBase/README.html">2. AI 芯片基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/01.cpu_base.html">2.1. CPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/02.cpu_isa.html">2.2. CPU 指令集架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/03.cpu_data.html">2.3. CPU 计算本质</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/04.cpu_latency.html">2.4. CPU 计算时延</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/05.gpu.html">2.5. GPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/06.npu.html">2.6. NPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/07.future.html">2.7. 超异构计算</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023HW_GPUBase/README.html">3. GPU 原理详解</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/01.works.html">3.1. GPU工作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/02.principle.html">3.2. 为什么 GPU 适用于 AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/03.base_concept.html">3.3. GPU架构与CUDA关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/04.fermi.html">3.4. GPU架构回顾第一篇</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/05.turing.html">3.5. GPU架构回顾第二篇</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024HW_NVIDIA/README.html">4. NVIDIA GPU详解</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/01.basic_tc.html">4.1. TensorCore原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/02.history_tc.html">4.2. TensorCore架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/03.deep_tc.html">4.3. TensorCore剖析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/04.basic_nvlink.html">4.4. 分布式通信与NVLink</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/05.deep_nvlink.html">4.5. NVLink原理剖析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/06.deep_nvswitch.html">4.6. NVSwitch原理剖析</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025HW_Abroad/README.html">5. 国外 AI 芯片架构</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/01.DOJO_Arch.html">5.1. 特斯拉DOJO架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/02.DOJO_Detail.html">5.2. 特斯拉DOJO Core原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/03.DOJO_System.html">5.3. 特斯拉DOJO存算系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/04.TPU_Introl.html">5.4. 谷歌TPU历史发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/05.TPU1.html">5.5. 谷歌TPUv1脉动阵列</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/06.TPU2.html">5.6. 谷歌TPUv2训练芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/07.TPU3.html">5.7. 谷歌TPUv3 POD形态</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/08.TPU4.html">5.8. 谷歌TPUv4三维互联</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026HW_Domestic/README.html">6. 国内 AI 芯片架构</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/01.BR100_System.html">6.1. 壁仞产品解读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/02.BR100_Detail.html">6.2. 壁仞BR100架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/03.SUIYUAN_DTU.html">6.3. 燧原产品与DTU架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/04.cambricon_Product.html">6.4. 寒武纪产品解读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/05.cambricon_Arch.html">6.5. 寒武纪MLU芯片架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/06.cambricon_Arch.html">6.6. 寒武纪MLU架构细节</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">==== 三、AI编译原理(更新中)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器(DOING)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 编译器基础介绍 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 传统编译器发展 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. TorchScript 静态图尝试</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">=== 四、推理系统&amp;引擎 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Framework/README.html">=== 五、AI框架核心模块 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053FW_DataFlow/README.html">3. 计算图(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">==== 六、大模型训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">=== 附录(DONE) ===</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">书写工具(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">书写规范(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">术语表(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">参考链接(DONE)</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="README.html">=== 一、AI系统概述 ===</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">AI 的历史，现状与发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="02drive.html">AI发展驱动力(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="03architecture.html">AI系统全栈架构(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="04sample.html">AI系统样例(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05principle.html">AI系统原则(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="06foundation.html">大模型的到来(待更)</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../020Hardware/README.html">=== 二、AI芯片体系结构 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021HW_Foundation/README.html">1. AI 计算体系概述</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/05.matrix.html">1.5. 核心计算之矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/06.bit_width.html">1.6. 计算之比特位宽</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022HW_ChipBase/README.html">2. AI 芯片基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/01.cpu_base.html">2.1. CPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/02.cpu_isa.html">2.2. CPU 指令集架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/03.cpu_data.html">2.3. CPU 计算本质</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/04.cpu_latency.html">2.4. CPU 计算时延</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/05.gpu.html">2.5. GPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/06.npu.html">2.6. NPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/07.future.html">2.7. 超异构计算</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023HW_GPUBase/README.html">3. GPU 原理详解</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/01.works.html">3.1. GPU工作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/02.principle.html">3.2. 为什么 GPU 适用于 AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/03.base_concept.html">3.3. GPU架构与CUDA关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/04.fermi.html">3.4. GPU架构回顾第一篇</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/05.turing.html">3.5. GPU架构回顾第二篇</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024HW_NVIDIA/README.html">4. NVIDIA GPU详解</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/01.basic_tc.html">4.1. TensorCore原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/02.history_tc.html">4.2. TensorCore架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/03.deep_tc.html">4.3. TensorCore剖析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/04.basic_nvlink.html">4.4. 分布式通信与NVLink</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/05.deep_nvlink.html">4.5. NVLink原理剖析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/06.deep_nvswitch.html">4.6. NVSwitch原理剖析</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025HW_Abroad/README.html">5. 国外 AI 芯片架构</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/01.DOJO_Arch.html">5.1. 特斯拉DOJO架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/02.DOJO_Detail.html">5.2. 特斯拉DOJO Core原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/03.DOJO_System.html">5.3. 特斯拉DOJO存算系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/04.TPU_Introl.html">5.4. 谷歌TPU历史发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/05.TPU1.html">5.5. 谷歌TPUv1脉动阵列</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/06.TPU2.html">5.6. 谷歌TPUv2训练芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/07.TPU3.html">5.7. 谷歌TPUv3 POD形态</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/08.TPU4.html">5.8. 谷歌TPUv4三维互联</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026HW_Domestic/README.html">6. 国内 AI 芯片架构</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/01.BR100_System.html">6.1. 壁仞产品解读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/02.BR100_Detail.html">6.2. 壁仞BR100架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/03.SUIYUAN_DTU.html">6.3. 燧原产品与DTU架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/04.cambricon_Product.html">6.4. 寒武纪产品解读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/05.cambricon_Arch.html">6.5. 寒武纪MLU芯片架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/06.cambricon_Arch.html">6.6. 寒武纪MLU架构细节</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">==== 三、AI编译原理(更新中)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器(DOING)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 编译器基础介绍 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 传统编译器发展 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. TorchScript 静态图尝试</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">=== 四、推理系统&amp;引擎 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Framework/README.html">=== 五、AI框架核心模块 ===</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053FW_DataFlow/README.html">3. 计算图(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">==== 六、大模型训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">=== 附录(DONE) ===</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">书写工具(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">书写规范(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">术语表(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">参考链接(DONE)</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--Copyright © ZOMI 适用于[License](https://github.com/chenzomi12/DeepLearningSystem)版权许可--><div class="section" id="ai">
<h1>AI 的历史，现状与发展<a class="headerlink" href="#ai" title="Permalink to this heading">¶</a></h1>
<p>本章将介绍 AI 的由来、现状和趋势，让大家能够了解 AI
应用的由来与趋势，为后面理解 AI
系统的设计形成初步的基础。在后面章节介绍的人工智能系统奠定基础，值得注意的是，这些系统设计原则大部分也适合于机器学习系统。</p>
<p>因为系统本身是随着上层应用的发展而不断演化的，从人工智能本身的发展脉络和趋势可以观察到：目前模型不断由小模型到大模型分布式训练、由单一的模型训练方式演化出针对特定应用的深度强化学习的训练方式、企业级人工智能模型生产由独占使用资源到组织多租共享
AI 集群资源进行模型训练；看 AI
算法模型结构本身的发展，训练与部署需求使得模型结构快速演变；执行与部署流程上，资源管理变得越来越复杂，给
AI
系统的设计和开发带来越来越大的挑战的同时，也充满了新的系统设计，研究与工程实践的机遇。</p>
<p>希望在后面的章节中，不仅能给读者带来较为系统化的 AI
知识，也希望能激发开发者对 AI 系统研究的兴趣，掌握相应的 AI
系统研究方法与设计原则，感知 AI 系统发展的趋势与脉络。</p>
<div class="section" id="id1">
<h2>AI 的基本概念<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<p>人工智能起源于上世纪五十年代，经历了几次繁荣与低谷，直到2016年谷歌旗下的
DeepMind 发布 AlphaGo
程序赢得与世界围棋冠军的比赛，大众对人工智能的关注与热情被重新点燃。</p>
<p>其实人工智能技术早在这个标志事件之前已经在工业界很多互联网公司中得到了广泛应用与部署。例如，搜索引擎服务中的排序、图片的检索、广告推荐等功能，背后都有人工智能模型的支撑。</p>
<p>在媒体中经常看到词汇：人工智能、机器学习、深度学习和神经网络。那么他们之间的关系是什么？</p>
<p>可以认为机器学习是实现人工智能的一种方法，而深度学习是一种实现机器学习的技术。由于目前深度学习技术取得了突破性进展，是人工智能
AI
中最为前沿和重要的技术，并不断在广泛的应用场景内取代传统机器学习模型（如语音识别，推荐系统等）。而伸进网络是深度学习的具体实现形态，使用神经网络模型来表示深度学习。</p>
<p>同时，由于 AI
系统自身设计挑战较高（如更大的规模、更大的超参数搜索空间、更复杂的模型结构设计），硬件厂商围绕其设计了大量的专有
AI 芯片（如GPU、TPU、NPU 等）对 AI
算法进行训练加速与部署推理，所以在之后的内容中主要介绍的<strong>人工智能系统（AI
System）</strong>，实际上是围绕深度学习而衍生和设计的系统，因此也叫做<strong>深度学习系统（Deep
Learning System）</strong>。</p>
<p>但是 AI
系统很多也可以应用于机器学习算法或使用机器学习算法，例如，自动化机器学习，集群管理系统等。同时这些系统设计方法具有一定的通用性，有些继承自机器学习系统或者可以借鉴用于机器学习系统。</p>
</div>
<div class="section" id="id2">
<h2>AI 的广泛应用<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>随着人工智能技术的发展与推广，人工智能逐渐在互联网、制造业、医疗、金融等不同领域有大范围的应用。</p>
<p>实际上，人工智能并不是一个独立的技术，而是结合各个行业的多样性与大规模的数据储备，通过<strong>数据驱动（Data-Driven）</strong>的方式应用到各个具体应用和对应的任务（如人脸识别，物体检测等）中的一系列技术。</p>
<p>上面提到的<strong>数据驱动</strong>的方式，意味着人工智能本身严重依赖于数据，所以最早取得人工智能技术大范围落地和应用的公司，本身储备了大量且多样的应用场景中的数据。以下面为例的行业中已经有越来越多的任务使用人工智能技术提升效果：</p>
<ul>
<li><p>互联网</p>
<p>谷歌、百度、微软必应（Bing）等公司通过人工智能技术进行更好的文本向量化，提升检索质量，同时人工智能进行点击率预测，获取更高的利润。</p>
</li>
<li><p>医疗</p>
<p>IBM
沃森（Watson）从海量的医学文献和病历中提取医生临床诊断经验，通过让人工智能模型学习掌握临床诊断方法，辅助医生进行诊断。</p>
</li>
<li><p>金融</p>
<p>通过反欺诈，关联分析，时序预测等算法可以较早识别风险，并预测未来发展趋势。</p>
</li>
<li><p>自动驾驶</p>
<p>通过物体检测模型能够进行更好的路标检测，道路线检测进而增强自动驾驶方案。</p>
</li>
<li><p>游戏</p>
<p>在游戏中可以通过强化学习技术进行对战，设计新的策略，提升游戏体验。</p>
</li>
</ul>
<p>综上所述，可以看到也是这些有应用与部署人工智能技术的公司都会在人工智能基础设施和系统上投入和研发，进而通过提升人工智能模型生产效率，更快的获取效果更好的模型进而获取领先优势，然后再通过业务场景反哺，获取更多的数据和加大研发投入，驱动人工智能系统与工具链的创新与发展。</p>
<p>人工智能的代表性框架 PyTorch 是 Facebook 开发，后续贡献给 Linux
开源基金会；TensorFlow
是谷歌（Google）从2016年开源，华为（HUAWEI）为了避免美国全面封锁 AI
领域推出自研的 AI 框架 MindSpore。</p>
<p>微软（Microsoft）、亚马逊（Amazon）、特斯拉（Tesla）等公司早已部署数以万计的
GPU 用于 AI 模型的训练，OpenAI 等公司不断挑战更大规模的分布式模型训练。</p>
<p>英伟达（NVIDIA）、华为（HUAWEI）、英特尔（Intel）、谷歌（Google）等公司不断根据
AI 模型特点设计新的 AI 加速器芯片和对应的AI加速模块，如张量核 Tensor
Core、脉动阵列等提供更大算力的 AI 加速器。</p>
</div>
<div class="section" id="id3">
<h2>AI 学习方法<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
<p>在展开 AI 系统设计之前，需要首先了解 AI
的原理与特点。将以下面图中的实例介绍 AI
是如何工作的。假定读者有一定机器学习经验，其中的一些概念暂不在本章过多解释，会在第
2 章中介绍机器学习，神经网络与 AI
的原理，让读者对整体的执行流程有更加深入的理解。</p>
<center></center><center><p>图 1.1.1 AI 方法</p>
</center><p>如图 1.1.1 所示，将深度神经网络的开发与工作模式抽象为以下几个步骤：</p>
<p>（1）确定 AI
模型的输入特征（Feature）与输出标签（Label）数据样本（Sample）：图中所示，本问题给
AI
模型输入图片（例如，图片中有狗，猫等），输出是图片的类别（是猫，是狗？）。用户需要提前准备好模型的输入输出数据，进而展开后续的模型训练。</p>
<p>（2）设计与开发模型结构：开发者通过编程框架开发了图中图中的模型结构，绿色线代表权重与白色圆代表的输入数据发生乘法操作。其中的<span class="math notranslate nohighlight">\(w_n\)</span>代表权重，也就是可以被学习和不断更新的数值。</p>
<p>（3）训练（Training）过程：训练过程是计算机根据一定的优化算法（例如，梯度下降（Gradient
Descent）算法）搜索出给定数据集下，预测效果最好的指定 AI
模型中对应模型权重。如图中上半部分所示，训练过程就是根据用户给定的带有标签(例如，图中的
Cat，Dog
等输出标签)的数据集，不断通过梯度下降算法，以下面的步骤学习出给定数据集下最优的模型权重<span class="math notranslate nohighlight">\(w_n\)</span>的取值。</p>
<p>（3.1）前向传播（Forward
Propagation）：由输入到输出完成整个模型中各个层的矩阵计算（例如，卷积层，池化层等），产生输出并完成损失函数计算。</p>
<p>（3.2）反向传播（Back
Propagation）：由输出到输入反向完成整个模型中各个层的权重和输出对损失函数的梯度求解。</p>
<p>（3.3）梯度更新（Weight
Update）：对模型权重通过梯度下降法完成模型权重针对梯度和指定学习率更新。</p>
<p>不断重复以上步骤（3.1）~（3.2），直到达到模型收敛或达到终止条件（例如，指定的迭代次数）。</p>
<p>当完成了模型训练，意味着在给定的数据集上，模型已经达到最佳或者满足需求的预测效果。如果开发者对模型预测效果满意，就可以进入模型部署进行推理和使用模型。</p>
<p>（4）推理（Inference）过程：推理（Inference）只需要执行训练过程中的前向传播过程即可。</p>
<p>（4.1）前向传播：如图中下半部分所示，由输入到输出完成整个模型中各个层的矩阵计算（例如，卷积层，池化层等），产生输出。例如本例中输入是狗的图片，输出的结果为向量，向量中的各个维度编码了图像的类别可能性，其中够的类别概率最大，判定为狗，后续应用可以根据输出类别信息再通过程序转换为人可读的信息。</p>
<p>后面章节将要介绍的 AI
系统，就是围绕以上负载的全生命周期的开发与执行各个环节，提供给算法工程师良好的模型设计和开发体验，极致的执行性能，保证安全性，以及应对更大规模的数据，更大的模型结构，更大的超参数搜索空间，多租的执行环境，同时利用新的加速器硬件特性，开掘硬件的极致算力。</p>
</div>
<div class="section" id="id4">
<h2>1.1.3 神经网络基本理论的奠定<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h2>
<center></center><center><p>图 1.1.2 神经网络的基本理论与发展 (图片引用自互联网)</p>
</center><p>虽然 AI
在今年取得了举世瞩目的进展与突破，但是其当前基于的核心理论神经网络等，在这波浪潮开始前已经基本奠定，并经历了多次的起起伏伏。神经网络作为
AI 的前身，经历了以下的发展阶段：</p>
<p>1943 年，神经科学家和控制论专家 Warren McCulloch 和逻辑学家 Walter Pitts
基于数学和阈值逻辑算法创造了一种神经网络计算模型。并发表文章 “A Logical
Calculus of the ideas Imminent in Nervous
Activity”<a class="reference external" href="#McCullochetal">[3]</a>。</p>
<p>1957 年，Frank Rosenblat
发明感知机（Perceptron）<a class="reference external" href="#perceptron">[4]</a>。奠定了之后 AI
的基本结构，其计算以矩阵乘加运算为主，进而影响了后续人工智能芯片和系统的基本算子类型，例如：英伟达的新款GPU就有为矩阵计算设计的专用张量核（Tensor
Core）。</p>
<p>1960 年，Bernard Widrow<a class="reference external" href="#adaline">[5]</a> 和 Hoff 发明了
Adaline/Madaline，首次尝试把线性层叠加整合为多层感知器网络。感知器本质上是一种线性模型，可以对输入的训练集数据进行二分类，且能够在训练集中自动更新权值。感知器的提出吸引了大量科学家对人工神经网络研究的兴趣，对神经网络的发展具有里程碑式的意义。为之后的多层
AI
的网络结构奠定了基础，进而后期不断衍生更深层的模型，产生大模型和模型并行等系统问题。</p>
<p>1969 年，Marvin Minsky 和 Seymour Papert 共同编写了一本书籍“Perceptrons:
an introduction to computational
geometry”<a class="reference external" href="#perceptronbook">[6]</a>，在书中他们证明了单层感知器无法解决线性不可分问题（例如：异或问题）。发现了当时的神经网络的两个重大缺陷：（1）基本感知机无法处理异或回路。（2）当时计算机的计算能力不足以用来处理复杂神经网络。神经网络的研究就此停滞不前。这也为后来
AI
的两大驱动力，提升硬件算力和模型通过更多的层和非线性计算（激活函数和最大池化等）增加非线性能力的演进埋下了伏笔。</p>
<p>1974 年，Paul Werbos 在博士论文“Beyond regression : new tools for
prediction and analysis in the behavioral
sciences”<a class="reference external" href="#paul">[7]</a>中提出了用误差反向传播来训练人工神经网络，使得训练多层神经网络成为可能，有效解决了异或回路问题。这个工作奠定了之后
AI 的训练方式， AI
训练系统中最为重要的执行步骤就是在不断的进行反向传播训练。同时 AI
的编程语言和框架为了支持反向传播训练，默认都提供自动微分（Automatic
Differentiation）的功能。</p>
<p>1986 年， AI （Deep Learning）一词由 Rina Dechter 于 1986 年 AAAI
论文“LEARNING WHILE SEARCHING IN
CONSTRAINT-SATISFACTION-PROBLEMS”<a class="reference external" href="#rina">[8]</a>引入机器学习社区。目前常常所说的人工智能系统主要以
AI 系统为代表性系统。</p>
<p>1989 年，Yann LeCun 在论文“Backpropagation Applied to Handwritten Zip
Code
Recognition”<a class="reference external" href="#lenet">[9]</a>提出了一种用反向传导进行更新的卷积神经网络，称为
LeNet 。启发了后续卷积神经网络的研究与发展。卷积神经网络为 AI
系统的重要负载，大多数的 AI
系统都需要在卷积神经网络上验证性能，在未来会看到很多 AI
系统的基准测试中也会引入大量的卷积神经网络。</p>
<p>20 世纪 90
年代中期统计学习登场，支持向量机开始成为主流，进入第二个低谷。</p>
<p>2006 年，Geoff Hinton、Ruslan Salakhutdinov、Osindero 的论文“Reducing
the Dimensionality of Data with Neural
Networks”<a class="reference external" href="#hinton">[10]</a>表明，多层前馈神经网络可以一次有效地预训练一层，依次将每一层视为无监督受限的玻尔兹曼（Boltzmann）机，然后使用监督反向传播对其进行微调，其论文主要研究深度信念网络（Deep
Belief Nets）的学习。</p>
<p>2009 年，李飞飞教授团队在佛罗里达州举行的 2009 年计算机视觉和模式识别
(CVPR) 会议上首次以海报的形式展示了他们的
<a class="reference external" href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a><a class="reference external" href="#imagenet">[11]</a>数据库，之后大量计算机视觉领域的经典模型在此数据库上进行验证，评测并演进。李飞飞于
2006 年产生想法并开始研究
<a class="reference external" href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a><a class="reference external" href="#imagenet">[11]</a>
。2007年，李飞飞与 WordNet
的创始人之一普林斯顿大学教授克里斯蒂安·费尔鲍姆会面，之后从 WordNet
的单词数据库开始构建
ImageNet，并使用了它的许多功能。作为普林斯顿大学的助理教授，李博士组建了一个研究团队，致力于
ImageNet 项目，其通过众包平台 <a class="reference external" href="https://www.mturk.com/">Amazon Mechanical
Turk</a> 的工作人员来进行标记。</p>
<p>2011 年 8 月，2011 年 8 月，微软研究院 Frank Seide, Gang Li, Dong Yu 在
Interspeech
的一篇论文<a class="reference external" href="#dongetal">[12]</a>首次介绍了“如何通过深度神经网络模型在会话语音转录（Conversational
Speech Transcription）上实现突破性进展。”这项技术在次年初的微软 TechFest
上进行了展示。在 2012 年 10 月，微软首席研究官 Rick Rashid
博士在天津举办的 “21 世纪的计算-自然而然”
会议上进一步展示了基于此技术在实时语音机器翻译的最新进展。现场的演示效果相比论文更让人身临其境和震撼，让即使是非从业人员也能感受到
AI 的潜力，并进一步带动研究与工程团队开启和展开更多的 AI
在不同应用领域的探索与实践。论文 “<a class="reference external" href="https://dl.acm.org/doi/10.5555/3042573.3042574">Conversational Speech Transcription
Using Context-Dependent Deep Neural
Networks</a>”
<a class="reference external" href="#dongetal">[3]</a>介绍了模型的的设计和实验结果，“其在单通道非特定人识别（Single-pass
Speaker-independent Recognition）基准测试上将相对错误率由 27.4% 降低到
18.5% ，相对错误率降低 33%，在其他 4 类任务中相对错误率降低
22–28%。此深度神经网络的训练任务是通过分布式系统（其设计了适合当前作业的张量切片与放置以及通信协调策略以加速训练）部署在多台配置有
NVIDIA Tesla GPGPU
的服务器，通过几百小时的分布式训练才得以完成。论文在最后致谢中提到 “Our
special thanks go to Ajith Jayamohan and Igor Kouzminykh of the MSR
Extreme Computing Group for access to a Tesla server farm, without which
this work would not have been possible.”，由此看到在 AI
领域算法团队与系统团队协作已经由来已久，算法与系统的协同设计将以往不可能完成的计算任务变为了可能，上层负载需求驱动系统发展与演化，系统支撑上层负载取得新的突破。”</p>
<p>2012 年 1 月，Google 的神经网络从 1000 万张 YouTube
视频的静止画面中学会了<a class="reference external" href="https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html">识别猫</a>。Google
的科学家通过连接 16,000
个计算机处理器创建了最大的机器学习神经网络之一，他们在互联网上将这些处理器松散开来自行学习，正是大规模系统互联更大的算力支撑了当时相比以往更大的数据和模型的训练。此工作
“<a class="reference external" href="https://dl.acm.org/doi/10.5555/3042573.3042641">Building high-level features using large scale unsupervised
learning</a>”
<a class="reference external" href="#Quocetal">[13]</a> 发表在 ICML ’12 会议上。</p>
<p>2012 年 9 月，Alex Krizhevsky，Ilya Sutskever 和 Geoffrey
Hinton，团队通过设计
<a class="reference external" href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">AlexNet</a><a class="reference external" href="#alexnet">[14]</a>
赢得 ImageNet 竞赛，深度神经网络开始再次流行。首次采用 ReLU
激活函数，扩展了 LeNet5 结构，添加 Dropout 层减小过拟合，LRN
层增强泛化能力/减小过拟合。这些新的模型结构和训练方法影响着后续的模型设计和系统优化，例如：激活函数和卷积层的内核融合计算等。其花费
5 到 6 天，采用 2 块 NVIDIA GTX 580 3GB GPUs 对计算进行加速，进而形成 AI
系统以 GPU 等加速器为主要计算单元的架构。</p>
<p>而截至到 2012
年这个时间点，基础架构的线索中，以英伟达（NVIDIA）为代表的芯片厂商已经连续发布了
Tesla，Fermi，<a class="reference external" href="https://en.wikipedia.org/wiki/Kepler_(microarchitecture)">Kepler</a>
架构系列商用 GPU 和多款消费级 GPU，这些 GPU 已经开始被研究工作引用加速
AI 算法与模型的研究，被业界公司用于人工智能产品。但同时从 AlexNet
工作中看到，作者目前还基于 CUDA API
进行编程实现了<a class="reference external" href="https://code.google.com/archive/p/cuda-convnet">cuda-convnet</a>，
AI 系统与工具伴随着 AI
算法与模型的突破与需求呼之欲出，在后面的章节中将会总结和展望 AI
系统本身的脉络，现状与发展。</p>
<p>在之后的时间里，以
<a class="reference external" href="https://www.image-net.org/">ImageNet</a>，等公开的各领域（例如，计算机视觉，自然语言处理）数据集为代表的各个应用领域的公开数据集或基准测试，驱动着以卷积神经网络，循环神经网络，变换器（Transformer），图神经网络为代表的
AI
模型网络结构的发展和创新。基准测试的好处是研究者从繁杂的应用问题建模和数据预处理工作跳出，能够在给定数据集上尽可能排除其他因素干扰，更为公平对比已有工作，并研发创新模型结构。在当前的社区工作中可以观察到，
AI 模型网络结构越来越深，新结构层出不穷，同时不断驱动 AI
系统的演化，在接下来的小节将介绍模型结构的现状和趋势。模型作为上层应用负载，是驱动系统演化的驱动力之一。关注模型结构和
AI
的应用场景变化，能够让系统研究者和工程师把握系统发展的趋势，并设计出符合潮流和应对未来变化的系统。</p>
</div>
<div class="section" id="id5">
<h2>1.1.4 AI 算法，模型的现状和趋势<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h2>
<p>目前 AI 模型有很多种类并在每年不断推出新的模型，如图 1.1.3
所示，以影响系统设计的视角将其简要归为以下一些代表性的类型。这些代表性的网络结构也是未来人工智能系统进行评测和验证所广泛使用的基准。同时一些新的结构的涌现，也不断推进一些新的系统设计。</p>
<center></center><center><p>图 1.1.3 AI 算法，模型的演化与趋势</p>
</center><p>基本模型结构类型：</p>
<ul class="simple">
<li><p>卷积神经网络（Convolutional Neural Network）</p>
<ul>
<li><p>以卷积层（Convolution Layer），池化层（Pooling
Layer），全连接层（Fully Connected
Layer）等算子（Operator）的组合形成的并在计算机视觉领域取得明显效果和广泛应用的模型结构。</p></li>
</ul>
</li>
<li><p>循环神经网络（Recurrent Neural Network）</p>
<ul>
<li><p>以循环神经网络，长短时记忆（LSTM）等基本单元组合形成的适合时序数据预测（例如，自然语言处理，语音识别，监控时序数据等）的模型结构。</p></li>
</ul>
</li>
<li><p>混合结构</p>
<ul>
<li><p>组合之前卷积神经网络和循环神经网络，进而解决如光学字符识别（OCR）等复杂应用场景的预测任务。</p></li>
</ul>
</li>
</ul>
<p>基础模型的典型算子已经被框架和底层硬件做了较多优化，但是 AI
模型已经不单纯只在算子层面产生变化，其从网络结构，搜索空间等方向演化出如下的新的趋势：</p>
<ul class="simple">
<li><p>更大的模型</p>
<ul>
<li><p>以变换器（Transformer）为基本结构的代表性预训练神经语言模型（Neural
Language Model），例如，BERT，GPT-3
等，在自然语言处理和计算机视觉等场景应用越来越广泛。其不断增加的层数和参数量，对底层系统内存管理，分布式训练和硬件设计提出了很大的挑战。</p></li>
</ul>
</li>
<li><p>更灵活的结构和建模能力</p>
<ul>
<li><p>图神经网络等网络不断抽象多样且灵活的数据结构（例如：图（Graph），树（Tree）等），应对更为复杂的建模需求。进而衍生了新的算子（例如：图卷积等）与计算框架（例如：图神经网络框架等）。</p></li>
</ul>
</li>
<li><p>更稀疏的模型结构与模型融合（Model Ensemble）</p>
<ul>
<li><p>以多专家模型（Mixture of Experts）简称 MoE 和 Pathways
模型结构为代表的模型融合结构让运行时的系统执行模型更加动态（Dynamic）和稀疏（Sparse），提升模型的训练效率减少训练代价，支持更多的任务。给系统设计静态分析带来了不小的挑战，同时驱动运用即时编译（Just
In Time Compiling）和运行期（Runtime）更加高效的调度与优化。</p></li>
</ul>
</li>
<li><p>更大规模的搜索空间</p>
<ul>
<li><p>用户定义更大规模的超参数与模型结构搜索空间，通过超参数搜索优化（HPO）与神经网络结构搜索（NAS）自动化找到最优的模型结构。自动化机器学习（AutoML）为代表的训练方式，衍生出多作业执行与多作业（Multi-Jobs）编排优化的系统需求。</p></li>
</ul>
</li>
<li><p>更多样的训练方式</p>
<ul>
<li><p>强化学习（Reinforcement
Learning）为代表的算法有比传统训练方式更为复杂的过程。其衍生出训练，推理，数据处理混合部署与协同优化的系统需求。</p></li>
</ul>
</li>
</ul>
<p>开发者一般通过Python和 AI 框架（Framework）（例如，PyTorch，TensorFlow
等）API书写和描述以上 AI 模型，声明训练作业和部署模型流程。框架以
<a class="reference external" href="https://pytorch.org/">PyTorch</a><a class="reference external" href="#pytorch">[15]</a> 和
<a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a><a class="reference external" href="#tensorflow">[16]</a>
等代表性框架用户较大。但是这些框架应对自动化机器学习，强化学习等多样执行方式，以及细分的应用场景显得越来越开发低效，不够灵活，需要用户手工做特定的一些优化，没有好的工具和系统的支撑，这些问题一定程度上会拖慢和阻碍算法工程师研发效率，影响算法本身的发展。</p>
<p>所以目前开源社区中也不断涌现针对特定应用领域而设计的框架和工具，例如，<a class="reference external" href="https://huggingface.co/">Hugging
Face</a><a class="reference external" href="#huggingface">[17]</a>
语言预训练模型动物园（Model
Zoo）和库，<a class="reference external" href="https://github.com/pytorch/fairseq">FairSeq</a><a class="reference external" href="#fairseq">[18]</a>自然语言处理中的序列到序列模型，<a class="reference external" href="https://github.com/open-mmlab/mmdetection">MMDetection</a><a class="reference external" href="#mmdetection">[19]</a>物体检测库，针对自动化机器学习设计的
<a class="reference external" href="https://github.com/microsoft/nni">NNI</a><a class="reference external" href="#nni">[20]</a>等，进而针对特定领域模型负载进行定制化设计和性能优化，并提供更简化的接口和应用体验。这其中快速获取用户的原因有一些是其提供了针对应用场景非常简化的模型操作，并提供模型中心快速微调相应的模型，有一些是因为其能支持大规模模型训练或者有特定领域模型结构的系统优化。之后可以观察到，系统设计本身需要各个环节通盘考量，无论是系统性能，还是用户体验，亦或是稳定性等指标，甚至在开源如火如荼发展的今天，开源社区运营也成为系统推广本身不可忽视的环节。接下来将在后面几个小节从不同的维度和技术层面展开人工智能系统的全景图。</p>
</div>
<div class="section" id="id6">
<h2>小结与讨论<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h2>
<p>本章主要围绕 AI
的历史现状和发展展开，对系统研究，需要要深刻理解上层计算负载特点，历史和趋势，才能将找到系统设计的真实需求问题和优化机会。</p>
<p>请读者思考当前模型之间有何差异，对系统的要求会有什么挑战？</p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">AI 的历史，现状与发展</a><ul>
<li><a class="reference internal" href="#id1">AI 的基本概念</a></li>
<li><a class="reference internal" href="#id2">AI 的广泛应用</a></li>
<li><a class="reference internal" href="#id3">AI 学习方法</a></li>
<li><a class="reference internal" href="#id4">1.1.3 神经网络基本理论的奠定</a></li>
<li><a class="reference internal" href="#id5">1.1.4 AI 算法，模型的现状和趋势</a></li>
<li><a class="reference internal" href="#id6">小结与讨论</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="README.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>=== 一、AI系统概述 ===</div>
         </div>
     </a>
     <a id="button-next" href="02drive.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>AI发展驱动力(待更)</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>