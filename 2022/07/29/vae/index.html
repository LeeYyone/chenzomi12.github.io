

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ZOMI酱">
  <meta name="keywords" content="">
  
    <meta name="description" content="当前的内容是梳理《Transformer视觉系列遨游》系列过程中引申出来的。目前最近在AI作画这个领域 Transformer 火的一塌糊涂，AI画画效果从18年的 DeepDream[1] 噩梦中惊醒过来，开始从2022年 OpenAI 的 DALL·E 2[2] 引来插画效果和联想效果都达到惊人效果。虽然不懂，但是这个话题很吸引ZOMI，于是就着这个领域内容来看看有什么好玩的技术点。  但是要">
<meta property="og:type" content="article">
<meta property="og:title" content="VAE：学习高维数据分布">
<meta property="og:url" content="http://example.com/2022/07/29/vae/index.html">
<meta property="og:site_name" content="ZOMI酱的博客">
<meta property="og:description" content="当前的内容是梳理《Transformer视觉系列遨游》系列过程中引申出来的。目前最近在AI作画这个领域 Transformer 火的一塌糊涂，AI画画效果从18年的 DeepDream[1] 噩梦中惊醒过来，开始从2022年 OpenAI 的 DALL·E 2[2] 引来插画效果和联想效果都达到惊人效果。虽然不懂，但是这个话题很吸引ZOMI，于是就着这个领域内容来看看有什么好玩的技术点。  但是要">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/vae/vae5.png">
<meta property="article:published_time" content="2022-07-29T13:45:16.000Z">
<meta property="article:modified_time" content="2022-07-30T01:13:06.237Z">
<meta property="article:author" content="ZOMI酱">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/images/vae/vae5.png">
  
  
  
  <title>VAE：学习高维数据分布 - ZOMI酱的博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"8By2Rh3UdwUFi0qNVg4Fv3Vw-gzGzoHsz","app_key":"8hmRi2M643gQvVkbyzQpQk4I","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ZOMI酱</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="VAE：学习高维数据分布"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-29 21:45" pubdate>
          2022年7月29日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          110 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">VAE：学习高维数据分布</h1>
            
            
              <div class="markdown-body">
                
                <p>当前的内容是梳理<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/543227883">《Transformer视觉系列遨游》</a>系列过程中引申出来的。目前最近在AI作画这个领域 Transformer 火的一塌糊涂，AI画画效果从18年的 DeepDream[1] 噩梦中惊醒过来，开始从2022年 OpenAI 的 DALL·E 2[2] 引来插画效果和联想效果都达到惊人效果。虽然不懂，但是这个话题很吸引ZOMI，于是就着这个领域内容来看看有什么好玩的技术点。</p>
<p><img src="/images/vae/painter1.png" srcset="/img/loading.gif" lazyload></p>
<p>但是要了解：<strong>Transformer 带来AI+艺术，从语言开始遇到多模态，碰撞艺术火花</strong> 这个主题，需要引申很多额外的知识点，可能跟 CV、NLP 等领域大力出奇迹的方式不同，AI+艺术会除了遇到 Transformer 结构以外，还会涉及到 VAE、ELBO、Diffusion Model等一系列跟数学相关的知识。</p>
<p>这里介绍的 AVE 是万里长征的第一步，<strong>VAE 希望训练一个生成模型 X&#x3D;g(Z)，这个模型能够将采样后的概率分布映射到训练集的概率分布</strong>。</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>之前天天听公司去年入职的搞 NLP 的同事说 VAE 怎么样怎么样，一直有留意但是没有注意，以为跟 AE 一样比较简单几层网络模型加一个 Reconstruct Loss。没想到看到论文《Auto-Encoding Variational Bayes》就蒙圈了，于是乎照样翻了网上很多资料，无一例外发现都很含糊，主要的感觉是公式写了一大通，老瓜子嗡嗡的，最后感觉自己搞明白了，但是看看代码实现发现怎么这么简单，刚才理解的公式都去哪里了？</p>
<p>这里面参考了很多文章，特别感谢博主 苏剑林 的图文讲解和 李宏毅 老师的视频。加上自己这段时间每天挂着个问号在脑袋旁边。感觉有点想明白了，于是赶紧积累下来，希望通过下面的文字把 VAE 梳理清楚。</p>
<p>下面列了几个跟 VAE 强相关的简单知识点，首先是 1）<strong>混合高斯模型</strong>主要是对高维的数据进行概率表示，2）而 <strong>KL 散度</strong>则是用来对比两个概率分布之间的差异，3）当AI具备了解数据的概率表示和数据的分布差异，那么是不是可以通过一个<strong>自动编码器</strong>来去模拟数据生成呢？</p>
<p>于是就有了下面三个基础知识点。</p>
<h2 id="GMM-混合高斯模型"><a href="#GMM-混合高斯模型" class="headerlink" title="GMM 混合高斯模型"></a>GMM 混合高斯模型</h2><p><strong>混合高斯模型（Gaussian Mixture Model，GMM）</strong> 指的是多个高斯分布函数的线性组合，理论上 GMM 可以拟合出任意类型的分布，通常用于解决同一集合下的数据包含多个不同的分布情况。</p>
<p>简单可以理解 GMM 是一种聚类算法，一般使用期望最大算法（Expectation Maximization，EM）进行估计。而 EM 算法通常用来估计参数的隐变量 z 的一种方法，它是一种迭代的方法，大致可以分为 E 步和 M 步：</p>
<ol>
<li><strong>期望 E 步</strong>：若参数 Θ 已知，则可根据训练数据推断出最优隐变量 z 的值；</li>
<li><strong>最大化 M 步</strong>：若 z 的值已知，则可方便的对参数 Θ 做极大似然估计，求得参数 Θ 值；</li>
</ol>
<p><img src="/images/vae/gmm.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="KL-散度"><a href="#KL-散度" class="headerlink" title="KL 散度"></a>KL 散度</h2><p><strong>KL散度（Kullback-Leibler divergence，KLD）</strong> 是对两个概率分布 P 和 Q 差别的非对称性的度量。一般来说 P 表示数据的真实分布，Q 表示数据的理论分布。如果两个分布属于同一概率分布（即它们相似）, 那么KL散度越小；反之, 则越大。</p>
<p>$$<br>D_{\mathrm{KL}}(P | Q)&#x3D;-\sum_{i} P(i) \log \frac{Q(i)}{P(i)}<br>$$</p>
<p>即按概率分布 P 求得的 P 和 Q 的对数商的平均值。</p>
<p><img src="/images/vae/kl.jpg" srcset="/img/loading.gif" lazyload></p>
<h2 id="AE-自动编码器"><a href="#AE-自动编码器" class="headerlink" title="AE 自动编码器"></a>AE 自动编码器</h2><p><strong>自编码器（auto encoder, AE）</strong> 是一类在半监督学习和非监督学习中使用的人工神经网络 ANN，其功能是通过将输入信息作为学习目标，对输入信息进行表征学习（representation learning）。</p>
<h3 id="AE-算法原理"><a href="#AE-算法原理" class="headerlink" title="AE 算法原理"></a>AE 算法原理</h3><p>自编码器比较好理解，直接看图就搞清楚了，主要是通常包括两部分：encoder（也称为识别网络）将输入转换成隐变量 z，decoder（也称为生成网络）将隐变量 z 表示转换成输出。</p>
<p><img src="/images/vae/ae1.png" srcset="/img/loading.gif" lazyload></p>
<p>回到那一年，Auto-Encoder 自编码器是1986年由 Rumelhart 提出，可用于高维复杂数据的处理, 它促进了神经网络的发展。自编码神经网络是一种无监督学习算法（训练示例未标注），它使用了BP反向传播算法，致力于使输出与输入越接近越好，而输入和输出相同则是使用了 Reconstruct Error，即最小化输入和输出之间的重构误差。</p>
<p>根据图示，AE的算法描述为：</p>
<ol>
<li><p><strong>Encoder</strong>：负责将输入数据进行压缩，n 维输入数据通过 Hidden layer 压缩成 m 维的数据（m &lt;&lt; n），即通过编码器学习一组参数，得到一个 latent space；</p>
</li>
<li><p><strong>Decoder</strong>：负责还原数据，在需要用到的时候尽可能地以损失最小的方式恢复原始数据。</p>
</li>
</ol>
<p>AE应用范围一般，但扩展能力很强，可以应用于机器学习中的数据降维、特征抽取和数据可视化分析，在CV领域的应用有文本检索、以图搜图、还可用于预训练，也可扩展并应用于生成模型。结构上在 NLP 领域衍生出了 Seq2Seq 架构，而 CV 领域则衍生出类似于 U-Net 架构啦。（虽然很基础，但是很有用哦）</p>
<p><img src="/images/vae/ae2.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="AE-算法问题"><a href="#AE-算法问题" class="headerlink" title="AE 算法问题"></a>AE 算法问题</h3><p>AE 主要是表达一个自编码器模型，但还不是真正意义上的生成模型。对于一个特定的生成模型，它一般应该满足以下两点：</p>
<ol>
<li>编码器和解码器是可以独立拆分表达（类比GAN的Generator和Discriminator）。</li>
<li>固定维度下任意采样出来的编码向量，都应该能通过解码器产生一个对应的数据。</li>
</ol>
<p>下面参考李宏毅老师的解释，换成我最近比较喜欢的二哈。假设使用一张二哈和另外一张二哈去训练一个AE，经过训练，模型能够很好地还原出这两张图片。接下来，我们在 latent space 上中间一点，即两张图片编码空间中间处任取一点，将这点交给解码器进行解码，直觉上会得到一张二哈串串的图片。不过呢，实际 那这个点去 decode 的时候会发现 AE 还原出来的图片不仅模糊而且还是乱码的。</p>
<p>为什么会出现这种现象？一个直观上的解释是AE的 Encoder 和 Decoder 都使用了 DNN，DNN是一个非线性的变换过程，因此在latent space上点与点之间transform往往没有规律可循。</p>
<p><img src="/images/vae/ae3.png" srcset="/img/loading.gif" lazyload></p>
<p>如何解决这个问题呢？一个思想就是引入噪声，扩大图片的编码区域，从而能够覆盖到失真的空白编码区。其实说白了就是通过增加输入的多样性从而增强输出的鲁棒性。当给输入图片进行编码之前引入一点噪声，那么就可以让每张图片的编码空间出现在绿色箭头范围内，这样一来所得到的 latent space 就能覆盖到更多的编码范围。此时再从中间点抽取去还原便可以得到一个比较理想的输出啦。</p>
<p><img src="/images/vae/ae4.png" srcset="/img/loading.gif" lazyload></p>
<p>虽然在AE的基础上为输入数据增添了一些噪声使得 latent space 能够覆盖到比较多的区域，但是还是有不少地方没有被覆盖到，比如上图右边黄色的部分因为离得比较远所以就没编码到。</p>
<p>因此，是不是可以尝试利用更多的噪音，使得对于每一个输入样本，它的编码都能够覆盖到整个编码空间？也就是说，对每一个样本取得其编码空间的高斯分布，多个分布合起来变成一个混合高斯分布，latent space 的泛化能力就更强呢？</p>
<p>到这里已经不知不觉就引入了 VAE 变分自编码器的核心思想啦。</p>
<h1 id="VAE-变分自编码器"><a href="#VAE-变分自编码器" class="headerlink" title="VAE 变分自编码器"></a>VAE 变分自编码器</h1><p>通常意义上的编码器 Encoder 可以对数据进行压缩，降噪之类的一些处理，但是实际上不能来生成任意数据。上面不是已经简单用二哈举了个小例子， VAE 可以生成隐变量 z，并且 z 是及含有数据信息又含有噪声，除了还原输入的样本数据以外，还可以用于生成新的数据。</p>
<p>这么一说，感觉 VAE 其实也是个生成模型（功能和 GAN 相似），的确，GAN 和 VAE 两个的目标基本是一致的：希望构建一个从隐变量 z 生成目标数据 X 的模型，但是实现上有所不同。更准确地讲，它们是假设 z 服从某些常见的分布（比如正态分布），然后希望训练一个模型 X&#x3D;g(Z)，这个模型能够将原来的概率分布映射到训练集的概率分布，也就是说，<strong>目的都是进行分布之间的变换。</strong></p>
<p>不过 VAE 采用的是概率的思想用神经网络迭代求解数据分布概率，GAN 直接用神经网络训练一个判别器。实际效果上，VAE 的鲁棒性比 GAN 更好，但是 GAN 在调优之后效果比 VAE更好，这也是 GAN 大火的原因。</p>
<p>ZOMI 先来学习 VAE 的数学模型结构（之所以称为数学模型结构而不是网络模型结构呢，是因为 VAE 是基于数学模型原理推导出来的，为了去计算或者逼近拟合后验概率 p(z|x) 从而引入的MLP）。</p>
<p><img src="/images/vae/vae1.png" srcset="/img/loading.gif" lazyload></p>
<p>从图中可以看到，VAE就是在原本的AE结构上，给编码添加合适的噪声。VAE 的输入是样本 X 通过编码器 Encoder 求得平均值 μ 和标准差 σ 的向量；然后通过采样得到隐向量 z，接着通过解码器 Decoder 得到输出 $\hat{x}$。</p>
<h2 id="Native-VAE"><a href="#Native-VAE" class="headerlink" title="Native VAE"></a>Native VAE</h2><p>VAE 看上去很简单，实际代码实心也很简单，Encoder 和 Decoder 都是用 MLP 来实现。难的在于为何要这么设计和计算。</p>
<p><img src="/images/vae/vae2.png" srcset="/img/loading.gif" lazyload></p>
<p>假设现在我们手头上，有一批数据样本 ${x_1,…,x_n}$，其整体用 $x$ 来描述，本想根据 ${x_1,…,x_n}$ 得到  $x$ 的分布 $p(x)$。如果能直接得到的话，那根据 $p(x)$ 来采样，就可以得到所有可能的样本 $\hat{x}$ 。这是一个终极理想的生成模型，要是真的这么直接那就没 VAE 什么事情了。</p>
<p>由 VAE 的模型结构，可以看到编码空间 $z$ 是由一个标准正态分布所产生的向量。实际上概率分布可以表示为：</p>
<p>$$<br>p(x)&#x3D;\int_{z}p(z)p(x \mid z) dz<br>\tag{1}<br>$$</p>
<p>上面公式中的 $p(x\mid z)$ 英文是 p of x given z 描述一个由 z 来生成 x 的模型，假设 z 服从正态分布，也就是 $p(z)&#x3D;\mathcal{N}(0, I)$。那么现在就可以从标准正太分布中采样一个 z，然后根据编码空间 z 计算出 x ，生成的 x 和真实样本 x 进行对比迭代优化求解，这就是最简单的生成模型。根据博主 苏剑林的理解，从新画了张图。</p>
<p><img src="/images/vae/vae3.png" srcset="/img/loading.gif" lazyload alt="vae的传统理解"></p>
<p>这里面有个问题，经过重新采样出来的 $z_k$，因为已经经过一个正态分布 $N(0, I)$ 的压缩处理，压缩后的 $z_k$ 就不再是对应着原来的 $x_k$ 了（已经经过编码压缩），如果直接最小化 $L(\hat{x}_k,x_k)^2$ 是很不合理的。</p>
<h2 id="Vanilla-VAE"><a href="#Vanilla-VAE" class="headerlink" title="Vanilla VAE"></a>Vanilla VAE</h2><p>上面的 Native VAE 中并没有使用 p(z) 是正态分布的假设，而是假设后验分布 $P(z \mid x)$ 符合正态分布，也就是经过编码 Encoder 得到的分布。</p>
<p>具体来说，给定一个真实样本 $x_k$，假设存在一个专属于样本 $x_k$ 的后验分布 $P(z\mid x_k)$，并进一步假设这个分布符合正态分布。之所以是后验分布，是因为 $P(z\mid x_k)$ 与 样本 $x_k$ 相关，从分布中采样出来的 z 可以还原回 $x_k$ 中。</p>
<p>现在对 latency space 随机采样 m 个点，其中 m 服从多项式分布 $p(x)$，每采样一个点 m，将其对应到一个高斯分布 $N(μ^m, σ^m)$，于是一个多项式分布利用高斯混合模型 GMM 可以表示为：</p>
<p>$$<br>p(x)&#x3D;\sum_{m} p(m) p(x \mid m)&#x3D;\int_{z}p(z)p(x \mid z) dz<br>\tag{2}<br>$$</p>
<p>我们知道正态分布有两组参数：分别是均值 $μ$ 和方差 $σ^2$，现在问题是怎么找到属于样本 $x_k$ 的正态分布 $p(z \mid x_k)$ 的均值和方差呢？这个时候神经网络就来了，可以用 MLP 来进行拟合。于是在 Encoder 阶段构建两个神经网络来计算均值 $μ$ 和方差 $σ^2$。</p>
<p>经过上面的推论，便可以将原先离散的、存在大量失真区域的编码方式，转换成连续有效的编码方式。根据 Z 来计算 X，即计算分布概率 $p(x \mid z)$。</p>
<p><img src="/images/vae/vae4.png" srcset="/img/loading.gif" lazyload alt="vae的传统理解"></p>
<p>下面就是 VAE 的 Encoder 和 Decoder 阶段的内容：</p>
<ol>
<li><p><strong>Encoder</strong>：利用神经网络 MLP 来求解 $μ(z)$ 和 $σ(z)$， 等价于求解 $p(x \mid z)$。</p>
</li>
<li><p><strong>Decoder</strong>：利用神经网络 MLP 来求解 $q(z|x)$，q 为GMM的分布。</p>
</li>
</ol>
<p>VAE 需要求解的目标为表达式 (2)，原则上希望分布 $p(x)$ 越大越好。根据最大似然估计，等价于求解：</p>
<p>$$<br>\operatorname{Maximum} L&#x3D;\sum_{x} \log p(x)<br>\tag{3}<br>$$</p>
<p>给定任意一个分布q，因为 $\int_{z} q(z \mid x) d z&#x3D;1$，所以可以推导出：</p>
<p>$$<br>\begin{aligned}<br>\log p(x) &amp;&#x3D; \int_{z} q(z \mid x) \log p(x) dz \<br>&amp;&#x3D; \int_{z} q(z \mid x) \log \left(\frac{p(z, x)}{p(z \mid x)}\right) dz \<br>&amp;&#x3D; \int_{z} q(z \mid x) \log \left(\frac{p(z, x)}{q(z \mid x)} \frac{q(z \mid x)}{p(z \mid x)}\right) dz \<br>&amp;&#x3D; \int_{z} q(z \mid x) \log \left(\frac{p(z, x)}{q(z \mid x)}\right) dz+\int_{z} q(z \mid x) \log \left(\frac{q(z \mid x)}{p(z \mid x)}\right) dz \<br>&amp;&#x3D; \int_{z} q(z \mid x) \log \left(\frac{p(z, x)}{q(z \mid x)}\right) dz+KL(q(z \mid x) | p(z \mid x))<br>\end{aligned}<br>\tag{4}<br>$$</p>
<p>上式右边一项为 $q(z \mid x)$ 和 $p(z \mid x)$ 这两个分布的 KL 散度，根据KL 散度公式的性质，可以知道右边 KL 项恒大于等于0，于是可以找到 $log p(x)$ 的 对数似然的下界（Evidence Lower Bound，ELBO），此时可以把最大化对数似然转化为最大化 ELBO。即：</p>
<p>$$<br>\log p(x) \geq \int_{z} q(z \mid x) \log \left(\frac{p(x \mid z) p(z)}{q(z \mid x)}\right) dz<br>\tag{5}<br>$$</p>
<p>这里把 ELBO 记作：</p>
<p>$$<br>L_{b}&#x3D;\int_{z} q(z \mid x) \log \left(\frac{p(x \mid z) p(z))}{q(z \mid x)}\right) dz<br>\tag{6}<br>$$</p>
<p>代入式 (4)，可写成：</p>
<p>$$<br>\log p(x)&#x3D;L_{b}+KL(q(z \mid x) | p(z \mid x))<br>\tag{7}<br>$$</p>
<p>有趣的地方来了，原本我们是求使得 $log p(x)$ 最大化的 $p(x \mid z)$， 现在转为同时求解 $p(x \mid z)$ 和 $q(z \mid x)$。为什么把一个简单的事情复杂化求解多个变量？下面我们观察下 $log p(x)$  和 $L_b$ 之间的关系。</p>
<p><img src="/images/vae/vae7.png" srcset="/img/loading.gif" lazyload></p>
<p>根据公式(2)，$Log p(x)$ 是固定的，如果调节 $q(z \mid x)$ 使得 $L_b$ 越大，那么 KL 散度就会越小。当两个分布 $q(z \mid x)$ 和 $p(x \mid z)$ 完全一致的时候，KL 散度为0，此时 ELBO $L_b$ 就等于 $Log p(x)$。</p>
<p>因为 $L_b$ 是 $Log p(x)$ 的下界，所以求解最大似然估计 $\operatorname{Maximum} L$ 等价于求解：</p>
<p>$$<br>\operatorname{Maximum} L_b<br>\tag{8}<br>$$</p>
<p>而调节 $p(x \mid z)$ 就是训练 Decoder 的过程；调节 $q(z \mid x)$ 变成训练 Encoder 的过程。下面继续打开 ELBO：</p>
<p>$$<br>\begin{aligned}<br>L_{b} &amp;&#x3D;\int_{z} q(z \mid x) \log \left(\frac{P(z, x)}{P(z \mid x)}\right) dz \<br>&amp;&#x3D;\int_{z} q(z \mid x) \log \left(\frac{P(x \mid z) P(z)}{q(z \mid x)}\right) dz \<br>&amp;&#x3D;\int_{z} q(z \mid x) \log \left(\frac{P(z)}{q(z \mid x)}\right) dz+\int_{z} q(z \mid x) \log P(x \mid z) dz \<br>&amp;&#x3D;-KL(q(z \mid x) | P(z))+\int_{z} q(z \mid x) \log P(x \mid z) dz<br>\end{aligned}<br>\tag{9}<br>$$</p>
<p>现在又把 $\operatorname{Maximum} L_b$ 转化为求解上式左边项 KL 散度的最小值，以及右半部分的最大值。对于右半部分实际上很好理解：</p>
<p>$$<br>\operatorname{Maximum} \int_{z} q(z \mid x) \log p(x \mid z) dz&#x3D;\operatorname{Maximum} E_{q(z \mid x)}[\log p(x \mid z)]<br>\tag{10}<br>$$</p>
<p>E 为期望，表示期望 Encoder 输出 $q(z \mid x)$ 的情况下 Decoder 输出 $p(x \mid z)$ 尽可能的大。即需要从编码器 Encoder 得到的隐变量空间中采样隐变量 z，对采样得到的隐变量 z 进行解码 Decoder，使得解码得到的 $\hat{x}$ 分布中，对应是输入 $x$ 的概率尽可能大。<br>对于左半部分，需要 $KL(q(z \mid x)|P(z))$ 尽可能小，即需要编码器 Encoder 得到的隐变量概率分布与隐变量的先验分布尽可能接近。</p>
<h2 id="重参数"><a href="#重参数" class="headerlink" title="重参数"></a>重参数</h2><p>最后是实现模型的一个技巧，英文名是 reparameterization trick，这里叫它做重参数吧。</p>
<p>其实很简单，就是要从 $p(z|x_k)$ 中采样一个 z_k 出来，尽管知道了 $p(z|x_k)$ 属于正态分布，但是均值方差都是靠 MLP 模型计算出来的，要靠这个过程反过来优化均值和方差的模型，但是对于“采样”这个操作是不可导的，而采样的结果却是可导。我们利用：</p>
<p>$$<br>\begin{aligned}<br>&amp; \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(z-\mu)^{2}}{2 \sigma^{2}}\right) d z \<br>&#x3D;&amp; \frac{1}{\sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(\frac{z-\mu}{\sigma}\right)^{2}\right] d\left(\frac{z-\mu}{\sigma}\right)<br>\end{aligned}<br>\tag{11}<br>$$</p>
<p>这说明 $(z−μ)&#x2F;σ&#x3D;ε$ 是服从均值为0、方差为1的标准正态分布，要同时把 dz 考虑进去，是因为乘上 dz 才算是概率，去掉 dz 是概率密度而不是概率。这时候我们得到：</p>
<blockquote>
<p>从 $N(μ,σ^2)$ 中采样一个 z，相当于从 $N(0,I)$ 中采样一个 ε，然后让 $Z&#x3D;μ+ε×σ$。</p>
</blockquote>
<p>于是，从 $N(μ,σ^2)$ 采样变成了从 $N(0,I)$ 中采样，然后通过参数变换得到从 $N(μ,σ^2)$ 中采样的结果。这样一来，“采样”这个操作就不用参与梯度下降了，改为采样的结果参与，使得整个模型变得可训练。</p>
<p><img src="/images/vae/vae5.png" srcset="/img/loading.gif" lazyload alt="为了使模型具有生成能力，vae要求每个p(Z_X)都向正态分布看齐"></p>
<p>用更加通俗的话来说就是，当编码器和解码器输出的分布都是高斯分布，且要求隐变量先验分布为 $\mathcal{N}(0,I)$ 时，VAE的训练过程如下图上半部分所示。然而上半部分中的采样过程会导致训练过程中计算重构误差 $|X-f(z)|^2$。得到的梯度无法反向传播到编码器。因此将采样过程修改为下图下半部分的形式，从直接采样目标变量，变成采样目标变量到分布均值的差，这样使得反向传播过程中梯度可以传递到编码器。</p>
<p><img src="/images/vae/vae6.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>数学原理和公式都写了很多，如果跟我一样还没有被劝退，那么我们估计到这里已经满足不了求知的欲望，希望来点代码刺激刺激。毕竟原理推导很复杂，代码实现一行调包，就感觉自己懂了。</p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>数据集对于模型训练非常重要，好的数据集可以有效提高训练精度和效率。数据处理使用非常经典的 MNIST 手写字体识别，示例中用到的MNIST数据集是由10类28∗28的灰度图片组成，训练数据集包含60000张图片，测试数据集包含10000张图片。</p>
<p><img src="/images/vae/code1.png" srcset="/img/loading.gif" lazyload></p>
<p>具体可以通过 pytroch 的 vision 套件来下载，比较简单，使用 torchvision.datasets 接口就可以啦。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><br>bs = <span class="hljs-number">100</span><br><span class="hljs-comment"># MNIST 手写字体下载</span><br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;./mnist_data/&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br>test_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;./mnist_data/&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=transforms.ToTensor(), download=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 数据加载</span><br>train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=<span class="hljs-literal">True</span>)<br>test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<p>下载的数据集文件的目录结构如下：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Text">./mnist/<br>├── test<br>│   ├── t10k-images-idx3-ubyte<br>│   └── t10k-labels-idx1-ubyte<br>└── train<br>    ├── train-images-idx3-ubyte<br>    └── train-labels-idx1-ubyte<br></code></pre></td></tr></table></figure>

<h2 id="AVE-模型结构"><a href="#AVE-模型结构" class="headerlink" title="AVE 模型结构"></a>AVE 模型结构</h2><p>上面数据集虽然使用的是 MNIST 手写字体，但是 VAE 的网络模型结构不是使用 LeNet 网络模型，而是很简单的 Encoder 与 Decoder。</p>
<p>Encoder 阶段并没有什么秘密，正如上面原理介绍一样，2个 fc 层后接一个 fc 层用于计算均值 mu，另外一个 fc 层用于计算方差 var。</p>
<p>Decoder 阶段更加粗暴，直接使用3个 fc 层最后端到端的还原回输入 x 所相对应的向量大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VAE</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x_dim, h_dim1, h_dim2, z_dim</span>):<br>        <span class="hljs-built_in">super</span>(VAE, self).__init__()<br><br>        <span class="hljs-comment"># encoder part</span><br>        self.fc1 = nn.Linear(x_dim, h_dim1)<br>        self.fc2 = nn.Linear(h_dim1, h_dim2)<br>        self.fc31 = nn.Linear(h_dim2, z_dim)<br>        self.fc32 = nn.Linear(h_dim2, z_dim)<br><br>        <span class="hljs-comment"># decoder part</span><br>        self.fc4 = nn.Linear(z_dim, h_dim2)<br>        self.fc5 = nn.Linear(h_dim2, h_dim1)<br>        self.fc6 = nn.Linear(h_dim1, x_dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encoder</span>(<span class="hljs-params">self, x</span>):<br>        h = F.relu(self.fc1(x))<br>        h = F.relu(self.fc2(h))<br>        <span class="hljs-keyword">return</span> self.fc31(h), self.fc32(h) <span class="hljs-comment"># mu, log_var</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decoder</span>(<span class="hljs-params">self, z</span>):<br>        h = F.relu(self.fc4(z))<br>        h = F.relu(self.fc5(h))<br>        <span class="hljs-keyword">return</span> F.sigmoid(self.fc6(h)) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sampling</span>(<span class="hljs-params">self, mu, log_var</span>):<br>        std = torch.exp(<span class="hljs-number">0.5</span>*log_var)<br>        eps = torch.randn_like(std)<br>        <span class="hljs-keyword">return</span> eps.mul(std).add_(mu) <span class="hljs-comment"># return z sample</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>          <span class="hljs-comment"># where z = mu + sigma * torch.randn_like(mu)</span><br>        mu, log_var = self.encoder(x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>))<br>        z = self.sampling(mu, log_var)<br>        <span class="hljs-keyword">return</span> self.decoder(z), mu, log_var<br></code></pre></td></tr></table></figure>

<p>上面的代码其实很简单的啦，不过其中有一个 <code>sampling</code> 函数比较有意思，它的输入是 encoder 之后的均值mu和方差var，然后对var求解得到标准差 std。然后使用标准差求 eps，最后通过高斯采样获得隐变量 z。即对应公式：</p>
<p>$$z&#x3D;μ+ε×σ$$</p>
<p>引用英语原文的意思，就是从均值为0、方差为1的正态分布中随机数的二维隐变量生成样本。</p>
<blockquote>
<p>Generated samples from 2-D latent variable with random numbers from a normal distribution with mean 0 and variance 1.</p>
</blockquote>
<p>最后就是构建 VAE 神经网络模型啦，输入是一个 1x784 的 tensor。为什么是 784？因为一张 MNIST 手写字体的小图片就是 28x28 &#x3D; 784。z 设置得比较小，也就一个 1x2 的 tensor，所以看看最后生成什么样的效果图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># build model</span><br>vae = VAE(x_dim=<span class="hljs-number">784</span>, h_dim1= <span class="hljs-number">512</span>, h_dim2=<span class="hljs-number">256</span>, z_dim=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>

<h2 id="优化器和损失函数"><a href="#优化器和损失函数" class="headerlink" title="优化器和损失函数"></a>优化器和损失函数</h2><p>优化器没有特殊的地方，直接采用 Adam 优化器就好啦，这个比较通用。不过损失函数就有点不一样啦，VAE的损失函数有两个部分：一个重构因子和一个正则化因子。</p>
<p>那么现在打开看看 损失函数，损失函数输入有点多，首先第一个 <code>recon_x</code> 是 VAE 网络模型生成输出（注意啦，不是预测输出），后面的三个入参就不用介绍啦。损失函数总体用下面这公式来表示：</p>
<p>$$<br>\mathcal{L}(\mathbf{x})\approx \frac{1}{n}\sum^{n}<em>{i&#x3D;1}\Bigg[\frac{1}{2}\sum^{k}</em>{j&#x3D;1}\Big[\mu^{2}(\mathbf{x}_i)+\sigma^{2}(\mathbf{x}_i)-\log\sigma^{2}(\mathbf{x}<em>i)-1\Big]-\sum^{L}</em>{l&#x3D;1}\Big[\log p(\mathbf{x}<em>i\mid\mathbf{z}</em>{i,l})\Big]\Bigg]<br>$$</p>
<p>实际上根据公式()，目标是最小化KL散度：</p>
<p>$$<br>Min \ KL(q(z \mid x) | p(z \mid x))&#x3D;Min \ \sum(\mu^{2}+\sigma^{2}-\log\sigma^{2})<br>$$</p>
<p>而上面的式子右半部分可以理解为：</p>
<p>$$<br>-\log p(\mathbf{x}_i\mid \mathbf{z}<em>i)&#x3D;-\Big[\sum^{784}</em>{j&#x3D;1}x_j\log \hat{x}_j + (1-x_j)\log(1-\hat{x}_j)\Big]<br>$$</p>
<p>上面这个公式其实认真看一看，发现其实就是Binary Cross Entropy loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python">optimizer = optim.Adam(vae.parameters())<br><span class="hljs-comment"># return reconstruction error + KL divergence losses</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_function</span>(<span class="hljs-params">recon_x, x, mu, log_var</span>):<br>    BCE = F.binary_cross_entropy(recon_x, x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>))<br>    KLD = <span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(mu.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>) + log_var.exp() - log_var - <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> BCE + KLD<br></code></pre></td></tr></table></figure>

<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>训练代码就没啥好讲的啦，Pytorch 都一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    vae.train()<br>    train_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, _) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        optimizer.zero_grad()<br>        recon_data, mu, log_var = vae(data)<br>        loss = loss_function(recon_data, data, mu, log_var)<br><br>        loss.backward()<br>        train_loss += loss.item()<br>        optimizer.step()<br><br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, batch_idx * <span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(train_loader.dataset),<br>                <span class="hljs-number">100.</span> * batch_idx / <span class="hljs-built_in">len</span>(train_loader), loss.item() / <span class="hljs-built_in">len</span>(data)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;====&gt; Epoch: &#123;&#125; Average loss: &#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss / <span class="hljs-built_in">len</span>(train_loader.dataset)))<br></code></pre></td></tr></table></figure>

<p>输出结果示例：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Text">rain Epoch: 1 [0/60000 (0%)]    Loss: 544.540078<br>Train Epoch: 1 [10000/60000 (17%)]    Loss: 184.232109<br>Train Epoch: 1 [20000/60000 (33%)]    Loss: 162.313955<br>Train Epoch: 1 [30000/60000 (50%)]    Loss: 165.958750<br>Train Epoch: 1 [40000/60000 (67%)]    Loss: 159.636836<br>Train Epoch: 1 [50000/60000 (83%)]    Loss: 157.480146<br>====&gt; Epoch: 1 Average loss: 178.0764<br></code></pre></td></tr></table></figure>

<h2 id="VAE-结果"><a href="#VAE-结果" class="headerlink" title="VAE 结果"></a>VAE 结果</h2><p>下面图中左边第一个是原始的MNIST 手写字体，那么后面的X-D 代表的是隐向量 z 的维度，可以看到啦维度越高能生成的数据越精确和清晰。</p>
<p><img src="/images/vae/code2.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>VAE虽然也称是AE（AutoEncoder）的一种，但它的做法是别具一格的。在VAE中，它的Encoder有两个，一个用来计算均值，一个用来计算方差。很意外的是 Encoder 不是用来做编码压缩的，是用来算样本的均值和方差，这真是大新闻了，均值和方差不都是统计量吗，怎么是用神经网络来算的？</p>
<p>事实上，我觉得 VAE 从让普通人望而生畏的变分和贝叶斯理论出发，最后落地到一个具体的模型中，虽然走了比较长的一段路，但最终的模型其实是很接地气的：它本质上就是在常规的自编码器的基础上，对 Encoder 的结果加上了 “高斯噪声”，使得结果 Decoder 能够对噪声有鲁棒性；而额外的KL loss（目的是让均值为0，方差为1），事实上就是相当于对 Encoder 的一个正则项，希望 Encoder 出来的向量均有零均值。</p>
<p>那另外一个Encoder（对应着计算方差的网络）的作用呢？它是用来动态调节噪声的强度的。直觉上来想，当 Encoder 还没有训练好时（重构误差远大于KL loss），就会适当降低噪声（KL loss增加），使得拟合起来容易一些（重构误差开始下降）；反之，如果 Decoder 训练得还不错时（重构误差小于KL loss），这时候噪声就会增加（KL loss减少），使得拟合更加困难了（重构误差又开始增加），这时候 Decoder 就要想办法提高它的生成能力了。</p>
<h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>[1] <a target="_blank" rel="noopener" href="https://deepdreamgenerator.com/">https://deepdreamgenerator.com/</a> Gkotzos, Konstantinos. “Google’s DeepDream: Algorithms on LSD.”</p>
<p>[2] Marcus, Gary, Ernest Davis, and Scott Aaronson. “A very preliminary analysis of DALL-E 2.” arXiv preprint arXiv:2204.13807 (2022).</p>
<p>[3] <a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/5253">变分自编码器|Scientific Spaces</a></p>
<p>[4] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112513743">无监督学习之VAE——变分自编码器详解</a></p>
<p>[5] <a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2018-08-12-vae/">From Autoencoder to Beta-VAE</a></p>
<p>[6] <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1JK4y1D7Wb?p=44&vd_source=26de035c60e6c7f810371fdfd13d14b6">李宏毅2022机器学习深度学习课程</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Transformer/">#Transformer</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>VAE：学习高维数据分布</div>
      <div>http://example.com/2022/07/29/vae/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ZOMI酱</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月29日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/31/ad05/" title="自动微分实现：反向OO实现自动微分（Pytroch核心机制）">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">自动微分实现：反向OO实现自动微分（Pytroch核心机制）</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/22/efficientformer/" title="EfficientFormer：轻量化ViT Backbone">
                        <span class="hidden-mobile">EfficientFormer：轻量化ViT Backbone</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.17/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"8By2Rh3UdwUFi0qNVg4Fv3Vw-gzGzoHsz","appKey":"8hmRi2M643gQvVkbyzQpQk4I","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
