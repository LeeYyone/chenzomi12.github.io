<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>3.5. 计算图的控制流实现 &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.6. 动态图与静态图转换" href="06.static_graph.html" />
    <link rel="prev" title="3.4. 计算图的调度与执行" href="04.dispatch.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="README.html"><span class="section-number">3. </span>计算图(DONE)</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">3.5. </span>计算图的控制流实现</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/023FW_DataFlow/05.control_flow.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/readme.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="README.html">3. 计算图(DONE)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.1.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.1.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.1.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.1.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.1.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.1.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.1.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.1.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.1.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.1.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.1.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.1.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.1.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.1.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.1.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.1.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.1.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.1.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.1.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.1.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.1.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.1.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.1.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.1.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.1.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.1.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.1.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.1.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.1.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.1.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.1.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.1.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.1.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.1.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.1.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.1.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.1.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.1.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.1.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.1.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.1.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.1.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.1.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.1.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.1.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/README.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/README.html">1. AI 计算体系</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/README.html">2. AI 芯片基础</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053HW_GPUBase/README.html">3. GPU 原理详解</a></li>
<li class="toctree-l1"><a class="reference internal" href="../054HW_GPUDetail/README.html">4. NVIDIA GPU原理</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">== 六、大模型训练 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.1.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.1.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.1.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.1.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.1.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.1.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.1.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.1.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/readme.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="README.html">3. 计算图(DONE)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.1.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.1.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.1.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.1.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.1.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.1.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.1.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.1.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.1.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.1.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.1.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.1.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.1.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.1.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.1.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.1.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.1.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.1.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.1.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.1.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.1.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.1.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.1.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.1.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.1.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.1.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.1.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.1.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.1.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.1.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.1.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.1.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.1.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.1.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.1.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.1.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.1.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.1.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.1.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.1.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.1.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.1.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.1.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.1.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.1.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/README.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/README.html">1. AI 计算体系</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/README.html">2. AI 芯片基础</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053HW_GPUBase/README.html">3. GPU 原理详解</a></li>
<li class="toctree-l1"><a class="reference internal" href="../054HW_GPUDetail/README.html">4. NVIDIA GPU原理</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">== 六、大模型训练 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.1.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.1.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.1.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.1.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.1.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.1.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.1.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.1.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="id1">
<h1><span class="section-number">3.5. </span>计算图的控制流实现<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<p>计算图在数学上作为一个有向无环图（DAG，Directed Acyclic
Graph），能够把神经网络模型的概念抽象出来作为同一描述，不过在计算机的编程中，会遇到很多
if、else、while、for
等控制流语句，有向无环图改如何表示控制流变成了计算图中一个很重要的问题。好处在于，引入控制流之后，开发者可以向计算图中引入分支选择以及循环控制逻辑，进而构造出更加复杂的神经网络模型结构。</p>
<p>目前，以 Pytorch 为例，它支持的仅仅是 Python Control Flow，即在 Python
层执行控制逻辑，而非计算图中支持控制流。这样就存在一个问题，如果要部署带
Control Flow 的模型就会比较困难，如何灵活部署带控制流的计算图到不支持
Python 的设备上？</p>
<blockquote>
<div><p>计算图中的控制流实现，与控制流图并不是一个概念。在计算机科学中，控制流图
(CFG) 是程序执行期间所有可能路径的图形表示。控制流图是由 Frances E.
Allen 发现的。他指出，Reese T. Prosser
之前曾使用布尔连接矩阵进行流分析。CFG
是许多编译器优化和静态分析工具不可或缺的一部分。</p>
</div></blockquote>
<div class="section" id="id2">
<h2><span class="section-number">3.5.1. </span>控制流<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>AI
框架作为一个可编程系统，在设计时一个首要设计选择是如何让开发者，能够独立于实现细节以最自然的方式描述出各类神经网络模型。描述的完备性不仅影响
AI
框架能所够支持的神经网络结构，决定了开发者在使用高级编程语言，去实现神经网络模型的灵活性，也影响
AI 框架后端优化的技术手段。</p>
<div class="section" id="id3">
<h3><span class="section-number">3.5.1.1. </span>背景<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<p>在计算机科学中，控制流（Control
Flow）定义了独立语句，指令，函数调用等执行或者求值的顺序。例如，根据函数A的输出值选择运行函数B或者C中的一个。</p>
<div class="figure align-default" id="id12">
<span id="dataflow-04-img1"></span><a class="reference internal image-reference" href="../_images/control_flow01.png"><img alt="../_images/control_flow01.png" src="../_images/control_flow01.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">图3.5.1 </span><span class="caption-text">控制流表达</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
<p>AI
框架把神经网络的计算过程，抽象为有向无环图。使用有向无环图描述神经网络计算的方式，符合算法开发者对神经网络的概念定义：算子间拓扑结构对学习特性有重要影响，可以通过计算图，方便地描述出大多数通过堆叠深度或多分枝形成的复杂神经网络。然而，随着神经网络算法的快速发展，一些新颖的神经网络结构很难自然地表示为纯计算图。</p>
<p>以 Transformer 结构的神经网络为例，来看看使用最自然地方式描述这些算法对
AI 框架会带来什么新的表示要求。Transformer
结构的神经网络算法中，图的左侧是一个通用 Transformer
结构的中关键步骤的计算示意图，通过堆叠 Transformer
结构使得网络模型层数更深，右侧对应了使用最自然的方式描述这一算法计算过程的伪代码。</p>
<div class="figure align-default" id="id13">
<img alt="../_images/transformer01.png" src="../_images/transformer01.png" />
<p class="caption"><span class="caption-number">图3.5.2 </span><span class="caption-text">Transformer结构</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>Transformer 是一种基于注意力机制的神经网络结构，由多个 Encoder 和
Decoder
堆叠而成，可以应用于各种自然语言处理任务。在具体应用时，可以根据任务的特点和需求，选择不同的
Transformer
架构来构建模型。从伪代码描述中可以看到，想要以通用的方式，自然地描述出Transformer的算法框架，均依赖于循环控制逻辑
<code class="docutils literal notranslate"><span class="pre">for</span></code>。</p>
</div>
<div class="section" id="id4">
<h3><span class="section-number">3.5.1.2. </span>难点<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>引入控制流将会使得计算图的构建以及前向传播带来很大的差异。</p>
<p>首先，计算图将变为动态的方式，分支选择以及循环控制流只有在真实运行的时候，才能够依据其依赖的数据输入来判断走哪个分支、是否结束循环。</p>
<p>其次，控制流引入的另一个难点在于循环控制流的实现。引入循环之后，原本的计算图在逻辑上出现了环，从而无法进行有效的拓扑排序。所以对于有控制流的计算图，前向计算和反向传播的实现要么抛弃拓扑排序这一思路，要么就要通过其他手段将循环进行拆解。</p>
<p>为了能够支持含有控制流结构的神经网络模型，AI
框架需要引入了对动态控制流这一语言结构（language
construct）的支持。目前基于计算图，在控制流解决方案上，主要采用了三类设计思路：</p>
<ul class="simple">
<li><p><strong>复用宿主语言</strong>：复用前端宿主语言的控制流语言结构，用前端语言中的控制逻辑驱动后端计算图的执行</p></li>
<li><p><strong>支持控制流原语</strong>：AI
框架的后端对控制流语言结构进行原生支持，计算图中允许计算流和控制流混合</p></li>
<li><p><strong>源码解析</strong>：前端对高级编程语言的代码进行解析称计算图，后端对控制流语言结构解析成子图，对计算图进行延伸</p></li>
</ul>
<p>复用宿主语言以PyTorch为典型代表，支持控制流原语以TensorFlow为典型代表，源码解析的方式则以MindSpore为典型代表。</p>
</div>
</div>
<div class="section" id="id5">
<h2><span class="section-number">3.5.2. </span>动态图<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h2>
<p>每一次执行神经网络模型，AI框架会依据前端编程语言描述，动态生成一份临时的计算图（实际为单算子），这意味着该实现方式下计算图是动态生成，并且过程灵活可变，该特性有助于在神经网络结构调整阶段提高效率，这种实现方式也被称为<strong>动态计算图</strong>。</p>
<div class="section" id="id6">
<h3><span class="section-number">3.5.2.1. </span>复用宿主语言<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<p>PyTorch 采用的是动态图机制 (Dynamic Computational Graph)，动态图使得
PyTorch
的调试变得十分简单，每一个步骤，每一个流程都可以被开发者精确的控制、调试、输出，甚至是在每个迭代都能够重构整个网络。</p>
<p>动态图中，通过复用宿主语言的控制流构建动态图，即复用 Python
等高级语言本身的控制流的执行方式。以 PyTorch
为代表，在实际执行计算的时候，当遇到if、else、for
等控制流语句的时候，使用 Python 在CPU的原控制执行方式，当遇到使用
PyTorch 表示神经网络的 API 时，才继续按照动态计算图的执行方式进行计算。</p>
<p>下面的代码是 Transformer 结构对应的动态图示例 PyTorch 代码，Transformer
的 Decoder 结构中通过 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环，堆叠 Decoder
模块，最后通过if来检查是否需要加入 <code class="docutils literal notranslate"><span class="pre">norm</span></code> 正则化层。此时 AI
框架不再维护一个全局的神经网络描述，神经网络变成具体的 Python
代码，后端的张量计算以库的形式提供，维持了与 numpy 类似的一致编程接口。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
                <span class="n">memory</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
                <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">memory_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">memory_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">tgt_is_causal</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">memory_is_causal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">_get_seq_len</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">batch_first</span><span class="p">)</span>
        <span class="n">tgt_is_causal</span> <span class="o">=</span> <span class="n">_detect_is_causal_mask</span><span class="p">(</span><span class="n">tgt_mask</span><span class="p">,</span> <span class="n">tgt_is_causal</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span>
                         <span class="n">memory_mask</span><span class="o">=</span><span class="n">memory_mask</span><span class="p">,</span>
                         <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">,</span>
                         <span class="n">memory_key_padding_mask</span><span class="o">=</span><span class="n">memory_key_padding_mask</span><span class="p">,</span>
                         <span class="n">tgt_is_causal</span><span class="o">=</span><span class="n">tgt_is_causal</span><span class="p">,</span>
                         <span class="n">memory_is_causal</span><span class="o">=</span><span class="n">memory_is_causal</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<blockquote>
<div><p>代码出自 PyTorch框架github官网
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/transformer.py">https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/transformer.py</a></p>
</div></blockquote>
<p>即使 PyTorch 2.X
版本出来，推出了图模式，能够生成真正的计算图，但是目前的方案中，遇到控制流，仍然会把网络模型切分成不同的子图来执行，遇到控制流会使用Python来执行调度。</p>
<p>复用宿主语言的方式，其<strong>优点</strong>在于：</p>
<ol class="arabic simple">
<li><p>由于用户能够自由地使用前端宿主语言 Python
代码中的控制流，即时输出张量计算的求值结果，有着更高的易用性；</p></li>
<li><p><strong>模型即代码</strong>，动态图使用声明式编程的方式，使得定义神经网络模型的计算就像普通编写真正的程序。</p></li>
</ol>
<p>这种复用宿主语言控制流语言驱动后端执行的方式有着更加友好的用户体验，但<strong>缺点</strong>也是明显的：</p>
<ol class="arabic simple">
<li><p>用户易于滥用前端语言特性，带来更复杂的性能问题；</p></li>
<li><p>计算图的执行流会在语言边界来回跳转，带来十分严重的运行时开销；</p></li>
<li><p>整体计算图把模型切分成按算子组成的小块，不利于神经网络模型大规模部署和应用；</p></li>
<li><p>控制流和数据流被严格地隔离在前端语言和后端编译优化之中，前端和后端执行不同的语言和编译体系，跨语言边界优化难。</p></li>
</ol>
</div>
</div>
<div class="section" id="id7">
<h2><span class="section-number">3.5.3. </span>静态图<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h2>
<p>AI框架静态地生成可以根据 Python
等前端高级语言描述的神经网络拓扑结构，以及参数变量等图层信息构建一个固定的计算图，这种实现方式也称为<strong>静态计算图</strong>。具体在
AI 框架中，利用反向微分计算梯度通常实现为计算图上的一个优化
Pass，给定前向计算图，以损失函数为根节点广度优先遍历前向计算图的时，便能按照对偶结构自动生成出反向计算图。</p>
<div class="section" id="id8">
<h3><span class="section-number">3.5.3.1. </span>控制流原语<a class="headerlink" href="#id8" title="Permalink to this heading">¶</a></h3>
<p>支持控制流原语以 TensorFlow
为典型代表，在面对控制流需求时，计算图中引入控制流原语，运行时对控制流原语以第一等级（first-class）进行实现支持。其控制流的基本设计原则是：引入包含少量操作的原子操作符（即
Function 类特殊算子），在这些操作符之上来表达TensorFlow
应用的复杂控制流。</p>
<p>TensorFlow
计算图中支持控制流的方案，主要分为3层。暴露给开发者用于构建计算图的前端API，这些API会被转换成更低等级的控制流原语，再由计算图优化器进一步进行改写。为了平衡编程的易用性和优化器设计中保留更多易于被识别出的优化机会，TensorFlow提供了多套有着不同抽象等级的前端API以及计算图上的控制流原语。</p>
<p>为了提高可理解性和编程效率避免开发者直接操作底层算子，这些计算图中的控制流原语会被封装为前端的控制流API，下图是用户使用前端基础控制流API编写带条件和循环的计算，以及它们所对应的计算图表示。为了简化开发者识别计算图中的控制结构，TensorFlow
基于底层控制流原语，引入高层 Functional
控制流算子，同时添加高层控制流算子向底层控制流算子的转换逻辑。</p>
<div class="figure align-default" id="id14">
<img alt="../_images/control_flow02.png" src="../_images/control_flow02.png" />
<p class="caption"><span class="caption-number">图3.5.3 </span><span class="caption-text">TensorFlow控制流API层</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<p>下面以循环嵌套两个 for 循环代码，使用 TensorFlow 2.X 的API为例子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">j</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="n">j</span><span class="p">])</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>TensorFlow的计算图，每个算子的执行都位于一个执行帧中（execution
frame）中，每个执行帧具有全局唯一的名字作为标识符，控制流原语负责创建和管理这些执行帧。可以将执行帧类比为程序语言中的域（Scope），其中通过key-value表保存着执行算子所需的上下文信息，如输入输出变量存储位置等。当计算图中引入控制流后，每个算子有可能被多次执行，控制流原语会在运行时创建这些执行帧，执行帧可以嵌套，对应了开发者写出的嵌套控制流。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># 具有全局唯一的名字作为标识符
execution frame：
{
    # 保存着执行算子所需的上下文信息
     key(ops_1): value(input_addr, output_addr, ops_attr),
     key(ops_2): value(input_addr, output_addr, ops_attr),
     ...
     # 嵌套Execution frame，可并发优化
     execution frame：{
     key(ops_1): value(input_addr, output_addr, ops_attr),
     key(ops_2): value(input_addr, output_addr, ops_attr),
     ...
    }
}
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>的循环体是一个用户自定义计算子图，对于每个 while
循环，TensorFlow 运行时会设置一个执行帧，并在执行帧内运行 while
循环的所有操作。执行帧可以嵌套。嵌套的 while
循环在嵌套的执行帧中运行。位于同一个计算帧中，嵌套的<code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>对应嵌套的计算帧，位于不同计算帧中的算子，只要它们之间不存在数据依赖，有能够被运行时调度并发执行。只要执行帧之间没有数据依赖关系，则来自不同执行帧的操作可以并行运行。</p>
<p>如下图所示，TensorFlow 的原子操作集之中有五个控制流原语运算符，其中
Switch 和 Merge 组合起来可以实现条件控制。所有五个基元一起组合则可以实现
while 循环。</p>
<div class="figure align-default" id="id15">
<img alt="../_images/control_flow03.png" src="../_images/control_flow03.png" />
<p class="caption"><span class="caption-number">图3.5.4 </span><span class="caption-text">TensorFlow控制流原语</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<p>其中：</p>
<ul class="simple">
<li><p>Switch：Switch 运算符会根据输入控制张量 p 的布尔值，将输入张量 d
转发到两个输入中的一个。只有两个输入都准备好之后，Switch
操作才会执行。</p></li>
<li><p>Merge：Merge
运算符将其可用的输入之一转发到其输出。只要它的任何一个输入可用，merge
运算符就会执行。如果有多个可用的输入，则无法确定它的输出。</p></li>
<li><p>Enter(name)：Enter
操作符将其输入转发到由给定名称唯一标识的执行帧。这个 Enter
操作用于将一个执行帧中的张量传递给一个子执行帧。对于同一个子执行帧可以有多个
Enter
操作，每个操作都会使子执行帧中的张量可用（异步）。当输入可用时，Enter
操作将执行。一个新的执行帧在执行该帧第一个 Enter 操作时候被实例化。</p></li>
<li><p>Exit：Exit
操作符将一个张量从一个执行帧返回给它的父执行帧。一个执行帧可以有多个
Exit 操作返回到父执行帧，每个操作都异步地将张量传回给父帧。当一个
Exit 的输入可用时，该 Exit 操作就被启用。</p></li>
<li><p>NextIteration: 一个 NextIteration
操作符将其输入转发到当前执行帧的下一个迭代。TensorFlow
运行时会跟踪维护执行帧中的迭代信息。一个执行帧中执行的任何操作都有一个唯一的迭代
ID，这使得我们能够唯一地识别迭代计算中同一操作的不同调用（比如 hile
操作之中，某一个 op 可能会多次执行）。</p></li>
</ul>
<p><strong>优点</strong>在与：</p>
<ol class="arabic simple">
<li><p>静态图由于能够在执行具体计算之前得到神经网络模型计算的全过程统一描述，使得
AI 编译器在编译优化期间能够利用计算图的信息进行优化</p></li>
<li><p>执行逻辑无需在前端宿主语言与运行时之间反复切换，因此往往有着更高的执行效率。</p></li>
</ol>
<p>不过这种方式也有其比较大的<strong>缺点</strong>：</p>
<ol class="arabic simple">
<li><p>由于控制流原语的语义设计，首要提升运行时的并发数和高效执行，与开发者在描述神经网络模型时候使用
Python 语法在编程习惯上差异较大，对开发者来说存在一定的易用性困扰</p></li>
<li><p>为了解决让开发者对细节控制原语不感知，需要对控制流原语进行再次封装，以控制流
API 的方式对外提供，这也导致了构建计算图步骤相对复杂。</p></li>
</ol>
</div>
<div class="section" id="id9">
<h3><span class="section-number">3.5.3.2. </span>源码解析<a class="headerlink" href="#id9" title="Permalink to this heading">¶</a></h3>
<p>源码解析的方式是：前端对高级编程语言的代码进行解析称计算图，后端对控制流语言结构解析成子图，对计算图进行延伸。具体实现的过程中，计算图对能够表达的控制直接展开，如
for
循环内部的内容，直接展开成带顺序的多个计算子图。另外通过创建子图进行表示，运行时时候动态选择子图执行，如遇到
if 和 else 的分支时候分别创建 2 张子图存放在内存，当 DSA
的控制模块判断需要执行 if 分支的时候，把通过 if
分支产生的子图产生的序列调度进入执行队列中。</p>
<p>通过对高级语言的源码解析成计算图，在对计算图进行展开的方式，其<strong>优点</strong>在于：</p>
<ol class="arabic simple">
<li><p>用户能够一定程度自由地使用前端宿主的控制流语言，即在带有约束的前提下使用部分Python代码；</p></li>
<li><p>解耦宿主语言与执行过程，加速运行时执行效率；</p></li>
<li><p>计算图在编译期得到全计算过程描述，发掘运行时效率提升点；</p></li>
</ol>
<p>因为属于静态图的方式，因此继承了声明式编程的<strong>缺点</strong>：</p>
<ol class="arabic simple">
<li><p>硬件不支持的控制流方式下，执行流仍然会在不同编程语言的边界来回跳转，带来运行时开销；</p></li>
<li><p>部分宿主的控制流语言不能表示，带有一定约束性；</p></li>
</ol>
</div>
</div>
<div class="section" id="id10">
<h2><span class="section-number">3.5.4. </span>总结<a class="headerlink" href="#id10" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>控制流采用不同设计，AI框架为声明式编程的静态图，以及命令式编程的动态图；</p></li>
<li><p>静态图统一DL表示利于编译优化和执行加速，但是灵活性和易用性受限；</p></li>
<li><p>动态图灵活复用宿主语言中的控制流原语，但是缺乏性能优化阶段；</p></li>
<li><p>基于追踪Trace或基于源代码解析可将动态图转换为静态图，兼顾易用性和性能；</p></li>
</ul>
</div>
<div class="section" id="id11">
<h2><span class="section-number">3.5.5. </span>视频<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h2>
<html><iframe src="https://player.bilibili.com/player.html?aid=303892102&amp;bvid=BV17P41177Pk&amp;cid=911665293&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;t=30&amp;autoplay=0" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></html></div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">3.5. 计算图的控制流实现</a><ul>
<li><a class="reference internal" href="#id2">3.5.1. 控制流</a><ul>
<li><a class="reference internal" href="#id3">3.5.1.1. 背景</a></li>
<li><a class="reference internal" href="#id4">3.5.1.2. 难点</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id5">3.5.2. 动态图</a><ul>
<li><a class="reference internal" href="#id6">3.5.2.1. 复用宿主语言</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id7">3.5.3. 静态图</a><ul>
<li><a class="reference internal" href="#id8">3.5.3.1. 控制流原语</a></li>
<li><a class="reference internal" href="#id9">3.5.3.2. 源码解析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id10">3.5.4. 总结</a></li>
<li><a class="reference internal" href="#id11">3.5.5. 视频</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="04.dispatch.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>3.4. 计算图的调度与执行</div>
         </div>
     </a>
     <a id="button-next" href="06.static_graph.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>3.6. 动态图与静态图转换</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>