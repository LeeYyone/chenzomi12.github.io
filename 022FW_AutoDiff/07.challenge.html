<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>2.1.7. 自动微分的挑战&amp;未来 &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. 计算图" href="../023FW_DataFlow/README.html" />
    <link rel="prev" title="2.1.6. 动手实现PyTorch微分" href="06.reversed_mode.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="README.html"><span class="section-number">2. </span>自动微分(DONE)</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">2.1.7. </span>自动微分的挑战&amp;未来</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/022FW_AutoDiff/07.challenge.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/readme.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="README.html">2. 自动微分(DONE)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">2.1.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.base_concept.html">2.1.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.grad_mode.html">2.1.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.implement.html">2.1.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.forward_mode.html">2.1.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.reversed_mode.html">2.1.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.1.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/README.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/README.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/README.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.1.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.1.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/README.html">6. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.1.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.1.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.1.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.1.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.1.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.1.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.1.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.1.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.1.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.1.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.1.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.1.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.1.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.1.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.1.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.1.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.1.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.1.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.1.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.1.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.1.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.1.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.1.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.1.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.1.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.1.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.1.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.1.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.1.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.1.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.1.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.1.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.1.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.1.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.1.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.1.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.1.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.1.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.1.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.1.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.1.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.1.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.1.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.1.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.1.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.1.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.1.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.1.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.1.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.1.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.1.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/README.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/README.html">1. AI 计算体系</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/README.html">2. AI 芯片基础</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053HW_GPUBase/README.html">3. GPU 原理详解</a></li>
<li class="toctree-l1"><a class="reference internal" href="../054HW_GPUDetail/README.html">4. NVIDIA GPU原理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/readme.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="README.html">2. 自动微分(DONE)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">2.1.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="02.base_concept.html">2.1.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.grad_mode.html">2.1.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.implement.html">2.1.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.forward_mode.html">2.1.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.reversed_mode.html">2.1.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.1.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/README.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/README.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/README.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.1.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.1.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/README.html">6. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.1.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.1.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.1.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.1.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.1.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.1.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.1.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.1.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.1.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.1.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.1.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.1.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.1.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.1.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.1.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.1.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.1.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.1.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.1.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.1.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.1.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.1.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.1.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.1.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.1.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.1.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.1.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.1.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.1.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.1.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.1.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.1.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.1.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.1.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.1.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.1.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.1.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.1.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.1.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.1.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.1.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.1.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.1.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.1.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.1.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.1.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.1.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.1.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.1.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.1.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.1.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/README.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/README.html">1. AI 计算体系</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/README.html">2. AI 芯片基础</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053HW_GPUBase/README.html">3. GPU 原理详解</a></li>
<li class="toctree-l1"><a class="reference internal" href="../054HW_GPUDetail/README.html">4. NVIDIA GPU原理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--适用于[License](https://github.com/chenzomi12/DeepLearningSystem/blob/main/LICENSE)版权许可--><div class="section" id="id1">
<h1><span class="section-number">2.1.7. </span>自动微分的挑战&amp;未来<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<p>在前面的章节里面，分别介绍了什么是自动微分、如何实现自动微分，以及更加深入的自动微分的基本数学原理，并贯以具体的代码实现例子来说明业界主流的AI框架在自动微分实现方法，希望让你更加好地掌握自动微分端到端能力。</p>
<p>虽然计算机实现自动微分已经发展了几十年，不过在自动微分的演进过程和未来发展，仍然遇到诸多挑战，这里主要总结两点：1）易用性；2）高效性能。针对这两点的改进，也是自动微分技术未来演进可以重点优化和改进的方向。</p>
<div class="section" id="id2">
<h2><span class="section-number">2.1.7.1. </span>易用性<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>易用性将是挑战的首位，是因为自动微分的数学原理比较固定，相对其他更加复杂的凸优化、群和商群等的数学原理而言，自动微分自动微分本身的数学原理相对简单，但其实现的难点在于：</p>
<ul class="simple">
<li><p>理想中的自动微分是对<strong>数学表达</strong>的分解、微分和组合过程</p></li>
<li><p>实际中的自动微分是对<strong>程序表达</strong>的分界、微分和组合过程</p></li>
</ul>
<p>而<strong>数学表达</strong>和<strong>程序表达</strong>之间存在显著的差异。</p>
<div class="section" id="id3">
<h3><span class="section-number">2.1.7.1.1. </span>控制流的表达<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<p>如下公式所示，为对公式 <span class="math notranslate nohighlight">\(l_1 = x\)</span> 具体的数学表达式进行多次展开：</p>
<div class="math notranslate nohighlight" id="equation-diff-07-eq0">
<span class="eqno">(2.1.40)<a class="headerlink" href="#equation-diff-07-eq0" title="Permalink to this equation">¶</a></span>\[\begin{split}𝑙_1=𝑥 \\ 𝑙_(𝑛+1)=4𝑙_𝑛 (1−𝑙_1) \\ 𝑓(𝑥)=𝑙_4=64𝑥(1−𝑥)(1−2𝑥)^2(1−8𝑥+8𝑥^2)^2\end{split}\]</div>
<p>在程序的实现过程中，并不会针对上述公式展开成：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f_3</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">l_1</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">l_2</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">l_1</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l_1</span><span class="p">)</span>
    <span class="n">l_3</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">l_2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l_1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">l_3</span>
</pre></div>
</div>
<p>在更加通用的场景，大部分开发者或者程序会更加习惯于使用 for
循环对代码进行累加乘：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="n">to</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">v</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span>
</pre></div>
</div>
<p>通过公式 <a class="reference internal" href="#equation-diff-07-eq0">(2.1.40)</a>
和对应的代码可以看出，在针对数学表达式中，递归属于一种隐式的存在，特别是针对下标及子表达式关系中。而在程序表达中，递归则显式的表达为语言中的
for 循环和入参 x。</p>
<p>虽然从计算的角度看二者是等价的（即数学计算过程相同及其计算结果相同），但是从自动微分的角度看却是截然不同。自动微分的计算机程序必须感知到
for i = 1 to 3 这个循环条件的计算过程和明确的入参 x
，这些并不属于开发者希望进行自动微分的部分。</p>
<p>换而言之，自动微分系统必须能够识别程序表达中用于计算控制流（例如for、while、loop、if、else等）的运算部分，并将其排除在微分过程外。</p>
<p>在主流的自动微分实现方法中，基本表达式法、操作符重载法的实现方案，好处在于：原生地只对特定的数据进行运算执行对应封装好的
API
或者操作符定义了自动微分规则，因此可以直接排除数学微分无关的控制流部分，只关注于具体的数学计算逻辑部分。</p>
<p>但是上述方法带来的问题，就是没有办法使用程序来表示闭包（closed
form）的数学表达式进行”自动微分”求解，打破了数学表示完整性，不能够将将整个问题转换为一个纯数学符号问题。此外通过代码转换法，则通常需要进行程序分析或微分规则的扩展定义来完成控制流部分的过滤处理。</p>
</div>
<div class="section" id="id4">
<h3><span class="section-number">2.1.7.1.2. </span>复杂数据类型<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>在数学表达式的微分过程中，通常处理的是连续可微的实数类型数据。然而在程序表达中，现代高级编程语言（Python、C/C++、JAVA等）通常提供了多种丰富特性，用于开发者自定义组合数据类型，如
tuple、record、struct、class、dict 等。</p>
<p>特别地，在这些封装的组合数据类型中，除了常规意义中可微的计算机浮点数据类型（如
FP32、FP16、INT8
等），还可能包含一些用于描述数据属性的字段，如索引值、名称、数据格式等等，而这些字段也应该被排除在微分过程外。</p>
<p>如下所示，针对源码转换法的第一性原理 ANF 定义和 Python、C++
都有其复杂的数学类型没有办法通过数学计算来表达。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&lt;aexp&gt;<span class="w"> </span>::<span class="o">=</span><span class="w"> </span>NUMBER<span class="w"> </span><span class="p">|</span><span class="w"> </span>STRING<span class="w"> </span><span class="p">|</span><span class="w"> </span>VAR<span class="w"> </span><span class="p">|</span><span class="w"> </span>BOOLEAN<span class="w"> </span><span class="p">|</span><span class="w"> </span>PRIMOP

Python<span class="w"> </span>::<span class="o">=</span><span class="w"> </span><span class="o">[</span>List,<span class="w"> </span>Enum,<span class="w"> </span>Tuple,<span class="w"> </span>Dict,<span class="w"> </span>DefaultDict<span class="o">]</span>
C++<span class="w"> </span>::<span class="o">=</span><span class="w"> </span><span class="o">[</span>size_t,<span class="w"> </span>whcar_t,<span class="w"> </span>enum,<span class="w"> </span>struct<span class="w"> </span>,<span class="w"> </span>STL::list<span class="o">]</span>
</pre></div>
</div>
<p>因此在实际的实现过程中，基本表达式法、操作符重载法一般只能通过预定义数据类型（如张量
Tensor
数据结构）来指定数据类型中哪些字段需要被微分，哪些不需要被微调，需要有更多的细节约束，开发者可定制的自由度较低。源码转换法则可以结合编译器或解释器的扩展来暴露一些接口给开发者，用于指定自定义数据类型的微分规则，但是灵活度太高实现起来不容易。</p>
</div>
<div class="section" id="id5">
<h3><span class="section-number">2.1.7.1.3. </span>语言特性<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h3>
<p>语言特性更多是关于设计，比如在设计一门高级的编程语言时，希望它有泛型有多态，实现过程中的特性就会包括泛型和多态。此外针对高级编程语言（High-level
programming language）可以作为一种独立于机器，面向过程或对象的语言。</p>
<p>因此，自动微分使用程序表达的实现过程中，开发者还可以有许多其他非原数学表达、非业务逻辑的代码，特别是针对高级编程语言的多态性、面向对象实现、异常处理、调试调优、IO
输入输出等代码及其高级特性，这些部分也需要被自动微分程序特殊处理。否则会造成数学表达和程序表达之间的混乱。</p>
<p>在早期的 TensorFLow1.X
版本针对自动微分的实现逻辑来看，其定义了明确的前后向 API
及其严格符号定义，需要按照一定的符号规则才能执行自动微分功能。开发者根据符号定义来写完成程序后，TensorFlow
执行时需要记住在前向传递过程中哪些运算以何种顺序发生。随后，在后向传递期间，TensorFlow
以相反的顺序遍历此运算列表来计算梯度。这就造成了TensorFLow
易用性成为诟病的原因之一。</p>
</div>
<div class="section" id="id6">
<h3><span class="section-number">2.1.7.1.4. </span>需求重写<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<p><strong>物理系统</strong>的可微分模拟可以帮助解决混沌理论、电磁学、地震学、海洋学等领域中的很多重要问题,
但又因为其对计算时间和空间的苛刻要求而对自动微分技术本身提出了挑战。</p>
<p>其中最大的技术挑战是对电磁学、海洋学和地震学等问题中最核心的微分方程求解过程的自动微分。这些微分方程常见的求解方法是先将问题的时空坐标离散化，并以数值积分的形式完成求解。要得到精确的结果，离散化后的网格需要设计得很稠密，从而对存储空间和计算时间的需求巨大。</p>
<p>与此同时, 在自动微分计算过程中，机器学习中主流的后向自动微分库，如 Jax
、 TensorFlow 和 PyTorch，需要很多额外的空间来缓存中间结果,
导致开发者无法直接用它们对具有一定规模的实际物理模拟问题求导。</p>
<p>针对诸如物理模拟、游戏引擎、气候模拟、计算机图形学中的应用等具有领域专用属性的自动微分程序，可能需要根据具体的需求，设计出适合该领域的自动微分程序实现。</p>
</div>
</div>
<div class="section" id="id7">
<h2><span class="section-number">2.1.7.2. </span>高效性能<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h2>
<p>在前面的章节中，介绍了自动微分在实际的计算实现过程，会涉及到程序的分解、微分和组合。因此如何对程序进行分解、微分和组合，及其执行顺序则会决定自动微分的性能。</p>
<div class="section" id="id8">
<h3><span class="section-number">2.1.7.2.1. </span>程序与微分表达<a class="headerlink" href="#id8" title="Permalink to this heading">¶</a></h3>
<p>首先我们看看程序和自动微分计算过程的简单实现方案。如对公式
<span class="math notranslate nohighlight">\(f(x)=x^3\)</span> 下面代码所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">t</span>
</pre></div>
</div>
<p>对公式进行微分可以表示为 <span class="math notranslate nohighlight">\(f'(x)=3x^2\)</span>，其微分的代码实现方式为：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dfun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">dx</span>
</pre></div>
</div>
<p>在计算机程序中，可以将原函数计算过程和微分结果过程进行融合，并完成类似公共子表达式的提取优化。如下面代码将同时完成原函数计算和微分结果计算：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">t</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">t</span>
    <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">dx</span>
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3><span class="section-number">2.1.7.2.2. </span>额外中间变量<a class="headerlink" href="#id9" title="Permalink to this heading">¶</a></h3>
<p>以在AI框架中更加常用的后向自动微分模式为例（目前作为更多AI框架的实现方式），其计算过程表达如图
<a class="reference internal" href="#autodiff01"><span class="std std-numref">图2.1.11</span></a>
所示，表的左列浅色为前向计算函数值的过程，与前向计算时相同，右面列深色为反向计算导数值的过程。</p>
<div class="figure align-default" id="id14">
<span id="autodiff01"></span><img alt="../_images/autodiff07.png" src="../_images/autodiff07.png" />
<p class="caption"><span class="caption-number">图2.1.11 </span><span class="caption-text">自动微分实现过程</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<p>反向模式的计算过程如图所示，其中：</p>
<div class="math notranslate nohighlight" id="equation-diff-07-eq1">
<span class="eqno">(2.1.41)<a class="headerlink" href="#equation-diff-07-eq1" title="Permalink to this equation">¶</a></span>\[\overline{v_i}=\dfrac{\delta y}{\delta v_i}\]</div>
<p>根据链式求导法则展开有：</p>
<div class="math notranslate nohighlight" id="equation-diff-07-eq2">
<span class="eqno">(2.1.42)<a class="headerlink" href="#equation-diff-07-eq2" title="Permalink to this equation">¶</a></span>\[\frac{\partial f}{\partial x}=\sum_{k=1}^{N} \frac{\partial f}{\partial v_{k}} \frac{\partial v_{k}}{\partial \boldsymbol{x}}\]</div>
<p>可以看出，左侧是源程序分解后得到的基本操作集合，而右侧则是每一个基本操作根据已知的求导规则和链式法则<strong>由下至上</strong>计算的求导结果。在求解最后的倒数过程中，左侧的源程序分解后的变量，与右侧的由下至上的计算过程中，存在大量的变量在过程中被多次复用。</p>
<p>以更加通用的数学表示为例则二阶微分方程的一般形式为：</p>
<div class="math notranslate nohighlight" id="equation-diff-07-eq3">
<span class="eqno">(2.1.43)<a class="headerlink" href="#equation-diff-07-eq3" title="Permalink to this equation">¶</a></span>\[𝐹(x, y, {y}', {y}'')=0\]</div>
<p>其中，<span class="math notranslate nohighlight">\(x\)</span> 是自变量，<span class="math notranslate nohighlight">\(y\)</span> 是未知函数，<span class="math notranslate nohighlight">\({y}'\)</span> 是
<span class="math notranslate nohighlight">\(y\)</span> 的一阶导数，<span class="math notranslate nohighlight">\({y}''\)</span> 是 <span class="math notranslate nohighlight">\(y\)</span>
的二阶导数。其二阶导数表示为：</p>
<div class="math notranslate nohighlight" id="equation-diff-07-eq4">
<span class="eqno">(2.1.44)<a class="headerlink" href="#equation-diff-07-eq4" title="Permalink to this equation">¶</a></span>\[\frac{\partial^{2} y }{\partial x^{2}} = \frac{\mathrm{d}}{\mathrm{d} y}\left (\frac{\mathrm{d} y}{\mathrm{d} x} \frac{\mathrm{d} x}{x} \right )\]</div>
<p>因此在复合求导函数中，会存在大量计算复用的情况。</p>
<p>额外中间变量存储得越多，会减少重复的计算量，即以空间换时间。在AI框架自动微分实现过程中，希望尽可能减少重复的计算，以更多的内存来存储额外产生的中间变量，这也是AI框架在实际执行网络模型计算的过程中，我们会遇到
NPU
的内存中除了模型权重参数、优化器参数以外，还会额外占用了很多的内存空间，这些内存空间就是用来存储上面所述的<strong>额外中间变量</strong>。</p>
</div>
<div class="section" id="id10">
<h3><span class="section-number">2.1.7.2.3. </span>重计算的方式<a class="headerlink" href="#id10" title="Permalink to this heading">¶</a></h3>
<p>自动微分的计算需要使用原程序计算的中间结果。在前向模式中，由于微分过程和原程序计算过程是同步的，因此不会引入额外的存储代价。但在反向模式中，必须将先执行原程序计算过程并将中间结果进行保存，再用于反向自动微分过程中。</p>
<p>因此，如何选择需要存储的程序中间结果点（check-point）将在很大程度上决定自动微分在运行速度和内存占用两项关键性能指标上的平衡表现。</p>
<p>如图 <a class="reference internal" href="#autodiff02"><span class="std std-numref">图2.1.12</span></a>
所示，从左向右的箭头表示原程序计算过程，而从右向左的箭头表示反向模式自动微分计算过程。圆圈点则表示所选择的中间结果存储点。</p>
<div class="figure align-default" id="id15">
<span id="autodiff02"></span><img alt="../_images/autodiff08.png" src="../_images/autodiff08.png" />
<p class="caption"><span class="caption-number">图2.1.12 </span><span class="caption-text">自动微分实现过程</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<p>图中左侧的策略为，将尽量少的存储中间结果，而当需要的时候，则会使用更早的中间结果进行重计算来得到当前所需的中间结果。图中右侧的策略即为，将尽可能多的存储每一步中间结果，因此当需要时，可以直接获得而不需重计算。</p>
<p>显然，上述两种策略即为在牺牲运行时间和牺牲内存占用间取得平衡，具体应该选择哪种复用策略取决于具体场景的需求和硬件平台的限制。</p>
<p>在AI框架的特性中，上述中间变量的存储过程其实被称为<strong>重计算</strong>的过程，也是在大模型训练或者分布式训练的过程中经过会使用到，根据不同的选择复用策略又叫做<strong>选择性重计算</strong>。</p>
</div>
</div>
<div class="section" id="id11">
<h2><span class="section-number">2.1.7.3. </span>自动微分未来<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h2>
<p>可微编程是将自动微分技术与语言设计、编译器 / 解释器甚至 IDE
等工具链等深度融合，将微分作为高级编程语言中第一特性（first-class
feature）。</p>
<p>而可微分编程是一种编程范型，在其中数值计算程序始终可通过自动微分来求导数。这允许了对程序中的参数的基于梯度优化（Gradient
method），通常使用梯度下降或其他基于高阶微分信息的学习方法。可微分编程用于各个领域，尤其是科学计算和人工智能。</p>
<p>目前大多数可微编程框架，通过构建包含程序中的控制流和数据结构的图来工作。尝试通常分为两组：基于静态和编译图的方法，例如
TensorFlow、Theano、MXNet 和
PaddlePaddle。这些往往有助于良好的编译器优化和扩展到大型系统，但它们的静态特性使它们交互性较差，并且更易于编写程序类型（例如包含循环和递归的程序）。不仅有限，而且用户也难以推理、有效地解释他们的程序。</p>
<p>名为 Myia 的概念验证编译器工具链使用 Python
的一个子集作为前端，并支持高阶函数、递归和高阶导数。支持运算符重载、基于动态图的方法，例如
PyTorch、 AutoGrad 和
MindSpore。它们的动态性和交互性使大多数程序更易于编写和推理。但是，它们会导致解释器开销（尤其是在组合许多小操作时）、可扩展性降低以及编译器优化带来的好处减少。</p>
<p>先前方法的局限性在于它只能区分以适当语言编写的代码，AI
框架方法限制了与其他程序的互操作性。一种新可微编程的方法通过从语言的语法或
IR 构造图形来解决此问题，从而允许区分任意代码。</p>
</div>
<div class="section" id="id12">
<h2><span class="section-number">2.1.7.4. </span>自动微分总结<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>自动微分挑战主要集中在易用性和性能两方面</p></li>
<li><p>易用性受限于控制流、数据类型等语言特性以外，还受限于领域需求</p></li>
<li><p>性能主要以程序表达与微分表达结合，编译，甚至高阶微分等引起</p></li>
</ul>
</div>
<div class="section" id="id13">
<h2><span class="section-number">2.1.7.5. </span>本节视频<a class="headerlink" href="#id13" title="Permalink to this heading">¶</a></h2>
<html><iframe src="https://player.bilibili.com/player.html?aid=558660226&amp;bvid=BV17e4y1z73W&amp;cid=909287382&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;t=30&amp;autoplay=0" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></html></div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">2.1.7. 自动微分的挑战&amp;未来</a><ul>
<li><a class="reference internal" href="#id2">2.1.7.1. 易用性</a><ul>
<li><a class="reference internal" href="#id3">2.1.7.1.1. 控制流的表达</a></li>
<li><a class="reference internal" href="#id4">2.1.7.1.2. 复杂数据类型</a></li>
<li><a class="reference internal" href="#id5">2.1.7.1.3. 语言特性</a></li>
<li><a class="reference internal" href="#id6">2.1.7.1.4. 需求重写</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id7">2.1.7.2. 高效性能</a><ul>
<li><a class="reference internal" href="#id8">2.1.7.2.1. 程序与微分表达</a></li>
<li><a class="reference internal" href="#id9">2.1.7.2.2. 额外中间变量</a></li>
<li><a class="reference internal" href="#id10">2.1.7.2.3. 重计算的方式</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id11">2.1.7.3. 自动微分未来</a></li>
<li><a class="reference internal" href="#id12">2.1.7.4. 自动微分总结</a></li>
<li><a class="reference internal" href="#id13">2.1.7.5. 本节视频</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="06.reversed_mode.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>2.1.6. 动手实现PyTorch微分</div>
         </div>
     </a>
     <a id="button-next" href="../023FW_DataFlow/README.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>3. 计算图</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>