<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>2.2. 什么是微分 &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.3. 微分计算模式" href="03.grad_mode.html" />
    <link rel="prev" title="2.1. 自动微分" href="01.introduction.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">2. </span>自动微分</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">2.2. </span>什么是微分</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/022FW_AutoDiff/02.base_concept.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/index.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/index.html">1. AI框架基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 自动微分</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computation_graph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 与自动微分关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/index.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/index.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/index.html">6. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/index.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/index.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/index.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/index.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/index.html">4. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/index.html">5. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/index.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/index.html">1. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/index.html">2. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/index.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/index.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/index.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/index.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/index.html">1. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/index.html">2. Kernel优化</a><ul class="simple">
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/index.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/index.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/index.html">1. AI框架基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">2. 自动微分</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computation_graph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 与自动微分关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/index.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/index.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/index.html">6. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/index.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/index.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/index.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/index.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/index.html">4. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/index.html">5. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/index.html">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/index.html">1. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/index.html">2. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/index.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/index.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/index.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/index.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/index.html">1. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/index.html">2. Kernel优化</a><ul class="simple">
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/index.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--适用于[License](https://github.com/chenzomi12/DeepLearningSystem/blob/main/LICENSE)版权许可--><div class="section" id="id1">
<h1><span class="section-number">2.2. </span>什么是微分<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<p>自动微分（Automatic
Differentiation，AD）是一种对计算机程序进行高效准确求导的技术，一直被广泛应用于计算流体力学、大气科学、工业设计仿真优化等领域。</p>
<p>近年来，机器学习技术的兴起也驱动着对自动微分技术的研究进入一个新的阶段。随着自动微分和其他微分技术研究的深入，其与编程语言、计算框架、编译器等领域的联系愈发紧密，从而衍生扩展出更通用的可微编程概念。也是作为AI框架核心的功能，被广泛地应用。</p>
<p>本章将从常见的微分方法开始介绍，然后深入自动微分基本概念。</p>
<div class="section" id="id2">
<h2><span class="section-number">2.2.1. </span>计算机求导方法<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<p>对计算机程序求导的方法可以归纳为以下四种：</p>
<ul class="simple">
<li><p><strong>手动求解法(Manual
Differentiation)</strong>：根据链式求导法则，手工求导并编写对应的结果程序，依据链式法则解出梯度公式，带入数值，得到梯度。</p></li>
<li><p><strong>数值微分法(Numerical
Differentiation)</strong>：利用导数的原始定义，通过有限差分近似方法完成求导，直接求解微分值。</p></li>
<li><p><strong>符号微分法(Symbolic
Differentiation)</strong>：基于数学规则和程序表达式变换完成求导。利用求导规则对表达式进行自动计算，其计算结果是导函数的表达式而非具体的数值。即，先求解析解，然后转换为程序，再通过程序计算出函数的梯度。</p></li>
<li><p><strong>自动微分法(Automatic
Differentiation)</strong>：介于数值微分和符号微分之间的方法，采用类似有向图的计算来求解微分值，也是本文介绍的重点。</p></li>
</ul>
<div class="figure align-default" id="id13">
<img alt="../_images/autodiff01.png" src="../_images/autodiff01.png" />
<p class="caption"><span class="caption-number">图2.2.1 </span><span class="caption-text">计算机程序求导的方法</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>下面详细对上面4种不同的计算机求导方法进行详细说明。</p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">2.2.2. </span>手动微分<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
<p>手动微分就是对每一个目标函数都需要利用求导公式手动写出求导公式，然后依照公式编写代码，带入数值，求出最终梯度。</p>
<p>这种方法准确有效，但是不适合工程实现，因为通用性和灵活性很差，每一次我们修改算法模型，都要修改对应的梯度求解算法。如果模型复杂或者项目频繁反复迭代，那么工作量将会是巨大的。</p>
<p>如图中Manual
Differentiation所示，会把原始的计算公式根据链式求导法则进行展开。</p>
</div>
<div class="section" id="id4">
<h2><span class="section-number">2.2.3. </span>数值微分<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h2>
<p>数值微分方式应该是最直接而且简单的一种自动求导方式，使用差分近似方法完成，其本质是根据导数的定义推导而来。</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[f'(x)=lim_{h \to 0}\frac{f(x+h)-f(x)}{h}\]</div>
<p>当 <span class="math notranslate nohighlight">\(h\)</span> 取很小的数值，比如 0.000001
时，导数是可以利用差分来近似计算出来的。只需要给出函数值以及自变量的差值，数值微分算法就可计算出导数值。单侧差分公式根据导数的定义直接近似计算某一点处的导数值。
观察导数的定义容易想到，当 <span class="math notranslate nohighlight">\(h\)</span> 充分小时，可以用差商
<span class="math notranslate nohighlight">\(\frac{f(x+h)-f(x)}{h}\)</span>
近似导数结果。而近似的一部分误差（截断误差，Truncation
Error）可以由泰勒公式中的二阶及二阶后的所有余项给出：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[f(x \pm h)=f(x)\pm hf'(x)+\frac{h^2}{2!}f''(x) \pm \frac{h^3}{3!}f''(x) + ... + (\pm h)^n n!f^{(n)}(x)\]</div>
<p>因此数值微分中常用的三种计算方式及其对应的截断误差可以归纳为三种。</p>
<ul class="simple">
<li><p>向前差商（Forward Difference）：</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta f(x)}{\delta x} \approx \frac{f(x+h)-f(x)}{h}\]</div>
<p>其中Forward Difference的阶段误差为 <span class="math notranslate nohighlight">\(O(h)\)</span>。</p>
<ul class="simple">
<li><p>向后差商（Reverse Difference）：</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta f(x)}{\delta x} \approx \frac{f(x)-f(x-h)}{h}\]</div>
<p>其中Reverse Difference的阶段误差为 <span class="math notranslate nohighlight">\(O(h)\)</span>。</p>
<ul class="simple">
<li><p>中心差商（Center Difference）</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta f(x)}{\delta x} \approx \frac{f(x+h)-f(x-h)}{2h}\]</div>
<p>其中Center Difference的阶段误差为 <span class="math notranslate nohighlight">\(O(h^2)\)</span>。</p>
<p>可以看出来，数值微分中的截断误差与步长 <span class="math notranslate nohighlight">\(h\)</span> 有关，<span class="math notranslate nohighlight">\(h\)</span>
越小则截断误差越小，近似程序越高。</p>
<p>但实际情况数值微分的精确度并不会随着 <span class="math notranslate nohighlight">\(h\)</span>
的减小而无限减小，因为计算机系统中对于浮点数的运算由于其表达方式存在另外一种误差（舍入误差，Round-off
Error），而舍入误差则会随着 <span class="math notranslate nohighlight">\(h\)</span> 变小而逐渐增大。</p>
<p>因此在截断误差和舍入误差的共同作用下，数值微分的精度将会形成一个变化的函数并在某一个
<span class="math notranslate nohighlight">\(h\)</span> 值处达到最小值。</p>
<p>为了缓解截断错误，提出了中心微分近似（Center Difference
Approximation），这方法仍然无法解决舍入误差，只是减少误差，但是它比单侧差分公式有更小的误差和更好的稳定性：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta f(x)}{\delta x} \approx \frac{f(x+h)-f(x-h)}{2h}+O(h^2)\]</div>
<div class="figure align-default" id="id14">
<a class="reference internal image-reference" href="../_images/autodiff02.png"><img alt="../_images/autodiff02.png" src="../_images/autodiff02.png" style="width: 700px;" /></a>
<p class="caption"><span class="caption-number">图2.2.2 </span><span class="caption-text">误差曲线</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<p>数值微分的优点是：</p>
<ul class="simple">
<li><p>具有计算适用性，对大部分表达式适用；</p></li>
<li><p>对用于显示地隐藏了求导过程；</p></li>
<li><p>简单容易实现。</p></li>
</ul>
<p>数值微分的缺点是：</p>
<ul class="simple">
<li><p>计算量大，求解速度最慢，因为每计算一个参数的导数，都需要重新计算。</p></li>
<li><p>引入误差，因为是数值逼近，所有会不可靠，不稳定的情况，无法获得一个相对准确的导数值。如果
<span class="math notranslate nohighlight">\(h\)</span> 选取不当，可能会得到与符号相反的结果，导致误差增大。</p></li>
<li><p>引入截断错误（Truncation error），在数值计算中 h
无法真正取零导致的近似误差。</p></li>
<li><p>引入舍入误差（Round-off
Error），在计算过程中出现的对小数位数的不断舍入会导致求导过程中的误差不断累积。</p></li>
</ul>
</div>
<div class="section" id="id5">
<h2><span class="section-number">2.2.4. </span>符号微分<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h2>
<p>符号微分（Symbolic
Differentiation）属符号计算的范畴，利用链式求导规则对表达式进行自动计算，其计算结果是导函数的表达式。符号计算用于求解数学中的公式解，得到的是解的表达式而非具体的数值。</p>
<p>符号微分适合符号表达式的自动求导，符号微分的原理是用下面的简单求导规则，对计算机程序中的表达式进行递归变换来完成求导替代手动微分：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta}{\delta x}((f(x)+g(x))=\frac{\delta}{\delta x}f(x)+\frac{\delta}{\delta x}g(x)\]</div>
<p>另外有：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\frac{\delta}{\delta x}(f(x)g(x))=(\frac{\delta}{\delta x}f(x))g(x)+f(x)(\frac{\delta}{\delta x}g(x))\]</div>
<p>由于变换过程中并不涉及具体的数值计算且数学上是严格等价，因此其可以大大减小微分结果的误差（仅存在变换完成后计算过程中的舍入误差）。除此之外，符号微分的计算方式使其还能用于类似极值
$ :raw-latex:<a href="#id6"><span class="problematic" id="id7">`</span></a>frac{delta}{delta x}`f(x)=0 $ 的数学问题求解。</p>
<p>从某种角度看，这种递归思想和严格的程序变换让符号微分看上去是一种“完美”的计算过程。</p>
<p>符号微分利用代数软件，实现微分的一些公式，然后根据基本函数的求导公式以及四则运算、复合函数的求导法则，将公式的计算过程转化成微分过程，这样就可以对用户提供的具有闭包（closed
form）的数学表达式进行”自动微分”求解。即先求解析解原始数学表达式，然后转换为程序，再通过程序计算出函数的梯度。</p>
<p>符号微分计算出的表达式需要用字符串或其他数据结构存储，如表达式树。因为符号微分的这些优点，其也在包括
Mathematica、Maple、matlab、Maxima 等现代代数系统工具软件中使用。</p>
<p>但符号微分的最大弊病在于其对表达式的严格展开和变换也导致了所谓的表达式膨胀（expression
swell）问题。以递归表达式为例：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[l_{n+1}=4l_n(1-l_n)\]</div>
<div class="figure align-default" id="id15">
<img alt="../_images/autodiff03.png" src="../_images/autodiff03.png" />
<p class="caption"><span class="caption-number">图2.2.3 </span><span class="caption-text">递归求导</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<p>可以看到在不同的迭代中其符号微分的结果相比人工简化后的结果复杂很多，且随着迭代次数而增大。</p>
<p>符号微分的优点是：</p>
<ul class="simple">
<li><p>简单容易实现；</p></li>
<li><p>精度高，可适用于更复杂的数学问题求解等场景。</p></li>
</ul>
<p>符号微分的缺点是：</p>
<ul class="simple">
<li><p>表达式复杂时候，求导结果存在表达式膨胀问题；</p></li>
<li><p>表达式必须是闭包（closed
form）形式，即必须能写成完整数学表达式，不能有编程语言中的循环结构、条件结构等，才能将整个问题转换为一个纯数学符号问题。</p></li>
</ul>
</div>
<div class="section" id="id8">
<h2><span class="section-number">2.2.5. </span>自动微分<a class="headerlink" href="#id8" title="Permalink to this heading">¶</a></h2>
<p>其实，对于机器学习中的应用，不需要得到导数的表达式，而只需计算函数在某一点处的导数值，即对应神经网络、深度学习在确定层数中某个神经元的导数值。</p>
<div class="section" id="id9">
<h3><span class="section-number">2.2.5.1. </span>基本原理<a class="headerlink" href="#id9" title="Permalink to this heading">¶</a></h3>
<p>自动微分是介于数值微分和符号微分之间的方法，采用类似有向图的计算来求解微分值。</p>
<ul class="simple">
<li><p>数值微分：直接代入数值近似求解；</p></li>
<li><p>符号微分：对代数表达式求解析解，再代入数值进行计算；</p></li>
<li><p>自动微分：对基本算子（函数）应用符号微分方法，其次代入数值进行计算，保留中间结果，最后通过链式求导法将中间结果应用于整个函数。这样可以做到完全向用户隐藏微分求解过程，也可以灵活于编程语言的循环结构、条件结构等结合起来。</p></li>
</ul>
<p>关于解析解我们还要做一些说明。几乎所有机器学习算法在训练或预测时，都可以归结为求解最优化问题，如果目标函数可导，则问题就变为求训练函数的驻点。但是通常情况下我们无法得到驻点的解析解，因此只能采用数值优化算法，如梯度下降法，牛顿法，拟牛顿法等等。</p>
<p>这些数值优化算法都依赖于函数的一阶导数值或二阶导数值（包括梯度与Hessian矩阵）。因此需要解决如何求一个复杂函数的导数问题，自动微分技术是解决此问题的一种通用方法。</p>
<p>由于自动微分法只对基本函数或常数运用符号微分法则，所以它可以灵活结合编程语言的循环结构，条件结构等。使用自动微分和不使用自动微分对代码总体改动非常小，由于它实际是一种图计算，可以对其做很多优化，所以该方法在现代深度学习系统中得到广泛应用。</p>
</div>
<div class="section" id="id10">
<h3><span class="section-number">2.2.5.2. </span>数学基础<a class="headerlink" href="#id10" title="Permalink to this heading">¶</a></h3>
<p>在计算链式法则之前，我们先回顾一下复合函数。复合函数在本质上就是有关函数的函数（function
of
functions）。它将一个函数的返回值作为参数传递给另一个函数，并且将另一个函数的返回值作为参数再传递给下一个函数，也就是函数套函数，把几个简单的函数复合为一个较为复杂的函数。</p>
<p>链式法则是微积分中的求导法则，用于求一个复合函数的导数，是在微积分的求导运算中一种常用的方法。复合函数的导数将是构成复合这有限个函数在相应点的
导数的乘积，就像锁链一样一环套一环，故称链式法则。</p>
<p>自动微分的思想则是将计算机程序中的运算操作分解为一个有限的基本操作集合，且集合中基本操作的求导规则均为已知在完成每一个基本操作的求导后，使用链式法则将结果组合得到整体程序的求导结果。即：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[(f \cdot g)'(x)=f'(g(x))g'(x)\]</div>
<p>比如对下式进行求导：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[y=sin(x^2+1)\]</div>
<p>链式求导，令：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[f(x)=sin(x),g(x)=x^2+1\]</div>
<p>有：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[(f(g(x)))'=f'(g(x))g'(x)=[sin(x^2+1)]' \cdot 2x=2cos(x^2+1) \cdot x\]</div>
</div>
<div class="section" id="id11">
<h3><span class="section-number">2.2.5.3. </span>自动微分精髓<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h3>
<p>自动微分的精髓在于它发现了微分计算的本质：微分计算就是一系列有限的可微算子的组合。</p>
<p>自动微分法被认为是对计算机程序进行非标准的解释。自动微分基于一个事实，即每一个计算机程序，不论它有多么复杂，都是在执行加减乘除这一系列基本算数运算，以及指数、对数、三角函数这类初等函数运算。</p>
<p>于是自动微分先将符号微分法应用于最基本的算子，比如常数，幂函数，指数函数，对数函数，三角函数等，然后代入数值，保留中间结果，最后再通过链式求导法则应用于整个函数。</p>
<p>通过将链式求导法则应用到这些运算上，我们能以任意精度自动地计算导数，而且最多只比原始程序多一个常数级的运算。</p>
<p>以如下为例，这是原始公式：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[y=f(g(ℎ(x)))=f(g(ℎ(w_0)))=f(g(w_1))=f(w_2)=w_3\]</div>
<p>自动微分以链式法则为基础，把公式中一些部分整理出来成为一些新变量，然后用这些新变量整体替换这个公式，于是得到：</p>
<div class="math notranslate nohighlight" id="equation-linear">
<span class="eqno">(2.2.15)<a class="headerlink" href="#equation-linear" title="Permalink to this equation">¶</a></span>\[\begin{split}w_0=x \\ w_1=h(w_0) \\ w_2=g(w_1) \\ w_3=f(w_2)=y\end{split}\]</div>
<p>然后把这些新变量作为节点，依据运算逻辑把公式整理出一张有向无环图（DAG）。即原始函数建立计算图，数据正向传播，计算出中间节点，并记录计算图中的节点依赖关系。</p>
<p>因此，自动微分可以被认为是将一个复杂的数学运算过程分解为一系列简单的基本运算，
其中每一项基本运算都可以通过查表得出来。</p>
<p>因此自动微分的优缺点可以简单总结如下：</p>
<ul class="simple">
<li><p>优点：精度高，无表达式膨胀问题；</p></li>
<li><p>缺点：需要存储一些中间求导结果，内存占用会增加。</p></li>
</ul>
</div>
</div>
<div class="section" id="id12">
<h2><span class="section-number">2.2.6. </span>本节视频<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h2>
<html><iframe src="https://player.bilibili.com/player.html?aid=345813308&amp;bvid=BV1Ld4y1M7GJ&amp;cid=911384582&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;t=30" width="100%" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe></html></div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">2.2. 什么是微分</a><ul>
<li><a class="reference internal" href="#id2">2.2.1. 计算机求导方法</a></li>
<li><a class="reference internal" href="#id3">2.2.2. 手动微分</a></li>
<li><a class="reference internal" href="#id4">2.2.3. 数值微分</a></li>
<li><a class="reference internal" href="#id5">2.2.4. 符号微分</a></li>
<li><a class="reference internal" href="#id8">2.2.5. 自动微分</a><ul>
<li><a class="reference internal" href="#id9">2.2.5.1. 基本原理</a></li>
<li><a class="reference internal" href="#id10">2.2.5.2. 数学基础</a></li>
<li><a class="reference internal" href="#id11">2.2.5.3. 自动微分精髓</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id12">2.2.6. 本节视频</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="01.introduction.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>2.1. 自动微分</div>
         </div>
     </a>
     <a id="button-next" href="03.grad_mode.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>2.3. 微分计算模式</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>