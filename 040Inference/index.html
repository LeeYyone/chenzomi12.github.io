<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>== 四、推理系统&amp;引擎 == &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. 模型轻量化" href="../041INF_Inference/index.html" />
    <link rel="prev" title="5.6. Dispatch 机制" href="../036CM_PyTorch/06.dispatch.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active">== 四、推理系统&amp;引擎 ==</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/040Inference/index.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/index.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/index.html">1. AI框架基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022FW_AutoDiff/index.html">2. 自动微分</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/01.introduction.html">2.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/04.implement.html">2.4. 微分实现方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computation_graph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 与自动微分关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/index.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/index.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/index.html">6. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/index.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/index.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/index.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/index.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/index.html">4. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/index.html">5. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/index.html">1. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/index.html">2. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/index.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/index.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/index.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/index.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/index.html">1. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/index.html">2. Kernel优化</a><ul class="simple">
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/index.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../020Framework/index.html">== 二、AI框架核心模块 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021FW_Foundation/index.html">1. AI框架基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022FW_AutoDiff/index.html">2. 自动微分</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/01.introduction.html">2.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/04.implement.html">2.4. 微分实现方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023FW_DataFlow/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/02.computation_graph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/03.atuodiff.html">3.3. 与自动微分关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/04.dispatch.html">3.4. 图优化与图执行调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023FW_DataFlow/06.future.html">3.6. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024FW_AICluster/index.html">4. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/02.architecture.html">4.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/03.communication.html">4.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/04.primitive.html">4.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024FW_AICluster/05.system.html">4.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025FW_AIAlgo/index.html">5. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/01.challenge.html">5.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/02.algorithm_arch.html">5.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025FW_AIAlgo/03.algorithm_sota.html">5.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026FW_Parallel/index.html">6. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/01.introduction.html">6.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/02.data_parallel.html">6.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/03.tensor_parallel.html">6.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/04.mindspore_parallel.html">6.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/05.pipeline_parallel.html">6.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/06.hybrid_parallel.html">6.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026FW_Parallel/07.summary.html">6.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/index.html">== 三、AI编译器原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/index.html">1. 传统编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 课程概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 编译器发展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/index.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/index.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans01.html">3.4. 布局转换原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/04.layout_trans02.html">3.5. 布局转换算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/05.memory.html">3.6. 内存分配算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/06.constant_fold.html">3.7. 常量折叠原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/07.cse.html">3.8. 公共表达式消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/08.dce.html">3.9. 死代码消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/09.algebraic.html">3.10. 代数简化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/10.summary.html">3.11. 优化Pass总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/index.html">4. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/index.html">5. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">== 四、推理系统&amp;引擎 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/index.html">1. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/index.html">2. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/index.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/index.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/index.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Hardware/index.html">== 五、AI芯片核心原理 ==</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051HW_Foundation/index.html">1. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/05.matrix.html">1.5. 核心计算：矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/06.bit_width.html">1.6. 数据单位：bits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052HW_ChipBase/index.html">2. Kernel优化</a><ul class="simple">
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/index.html">1. == 附录 ==</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">1.1. 书写工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">1.2. 书写规范</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">1.3. 术语表</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">1.4. 参考链接</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--Copyright © ZOMI 适用于[License](https://github.com/chenzomi12/DeepLearningSystem)版权许可--><div class="section" id="id1">
<h1>== 四、推理系统&amp;引擎 ==<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<p>训练过程通过设定数据处理方式，并设计合适的网络模型结构以及损失函数和优化算法，在此基础上将数据集以小批量（mini-batch）反复进行前向计算并计算损失，然后反向计算梯度利用特定的优化函数来更新模型，来使得损失函数达到最优的结果。训练过程最重要的就是梯度的计算和反向传播。</p>
<p>而推理就是在训练好的模型结构和参数基础上，做一次前向传播得到模型输出的过程。相对于训练而言，推理不涉及梯度和损失优化。推理的最终目标是将训练好的模型部署生产环境中。真正让
AI
能够运用起来。推理引擎可以将深度学习模型部署到云（Cloud）端或者边缘（Edge）端，并服务用户的请求。模型训练过程好比是传统软件工程中的代码开发的过程，而开发完的代码势必要打包，部署给用户使用，那么推理系统就负责应对模型部署的生命周期中遇到的挑战和问题。</p>
<p>当推理系统将完成训练的模型进行部署，并在服务时还需要考虑设计和提供负载均衡，请求调度，加速优化，多副本和生命周期管理等支持。相比深度学习框架等为训练而设计的系统，推理系统不仅关注低延迟，高吞吐，可靠性等设计目标，同时受到资源，服务等级协议（Service-Level
Agreement），功耗等约束。本章将围绕深度学习推理系统的设计，实现与优化内容展开，同时还会在最后介绍部署和
MLOps 等内容。</p>
<p>移动端的推理引擎应该挺多的了，google在2017年推出了TF-Lite，腾讯在2017年推出了ncnn，Apple在2017也推出了CoreML，阿里在2018年推出了MNN，华为2019年推出了MindSpsore-Lite。距今已经过去了快5年的时间，技术上也接近收敛。下面让我们一起打开推理引擎的技术吧！</p>
<div class="section" id="id2">
<h2>课程简介<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>《推理系统》推理系统是本分享的重点概述，推理就是在训练好的模型结构和参数基础上，执行前向传播得到模型输出的过程。相对于训练而言，推理不涉及梯度和损失优化。推理的最终目标是将训练好的模型部署生产环境中，真正让
AI
能够运用起来。推理引擎可以将深度学习模型部署到云（Cloud）端或者边缘（Edge）端，并服务用户的请求。模型训练过程好比是传统软件工程中的代码开发的过程，而开发完的代码势必要打包，部署给用户使用，那么推理系统就负责应对模型部署的生命周期中遇到的挑战和问题。</p></li>
<li><p>《轻量网络》在端侧推理引擎中，主要是执行轻量的模型结构。主要思想是针对神经网络模型设计更高效的网络计算方式，从而使神经网络模型的参数量减少的同时，不损失网络精度，并进一步提高模型的执行效率。本节主要集中介绍模型小型化中需要注意的参数和指标，接着深入了解CNN经典的轻量化模型和Transformer结构的轻量化模型。</p></li>
<li><p>《模型压缩》模型压缩跟轻量化网络模型不同，压缩主要是对轻量化或者非轻量化模型执行剪枝、蒸馏、量化等压缩算法和手段，使得模型更加小、更加轻便、更加利于执行。</p></li>
<li><p>《模型转换&amp;优化》在这一节当中分为模型转换和模型优化，在整体架构图中属于离线模型转换模块。一方面，推理引擎需要把不同
AI
框架训练得到的模型进行转换；另外一方面需要对转换后的模型进行图优化等技术。</p></li>
<li><p>《Kernel优化》在上层应用或者 AI
网络模型中，看到的是算子；但是在推理引擎实际执行的是具体的
Kernel，而推理引擎中 CNN 占据了主要是得执行时间，因此其 Kernel
优化尤为重要。</p></li>
</ul>
<p>希望这个系列能够给大家、朋友们带来一些些帮助，也希望自己能够继续坚持完成所有内容哈！</p>
</div>
<div class="section" id="id3">
<h2>课程细节<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h2>
<blockquote>
<div><p><em>建议优先下载或者使用PDF版本，PPT版本会因为字体缺失等原因导致版本很丑哦~</em></p>
</div></blockquote>
<div class="section" id="id4">
<h3>推理系统<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《推理系统》推理系统是本分享的重点概述，推理就是在训练好的模型结构和参数基础上，执行前向传播得到模型输出的过程。相对于训练而言，推理不涉及梯度和损失优化。推理的最终目标是将训练好的模型部署生产环境中，真正让
AI
能够运用起来。推理引擎可以将深度学习模型部署到云（Cloud）端或者边缘（Edge）端，并服务用户的请求。模型训练过程好比是传统软件工程中的代码开发的过程，而开发完的代码势必要打包，部署给用户使用，那么推理系统就负责应对模型部署的生命周期中遇到的挑战和问题。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分类</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>内容</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>推理系统</p></td>
<td><p>01 内容介绍</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1J8411K7pj/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>推理系统</p></td>
<td><p>02 推理系统介绍</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1nY4y1f7G5/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>推理系统</p></td>
<td><p>03 推理流程全景</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1M24y1v7rK/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>推理系统</p></td>
<td><p>04 推理系统架构</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Gv4y1i7Tw/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>推理系统</p></td>
<td><p>05(上) 推理引擎架构</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Mx4y137Er/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>推理系统</p></td>
<td><p>05(下) 推理引擎架构</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1FG4y1C7Mn/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id5">
<h3>模型轻量化<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《轻量网络》在端侧推理引擎中，主要是执行轻量的模型结构。主要思想是针对神经网络模型设计更高效的网络计算方式，从而使神经网络模型的参数量减少的同时，不损失网络精度，并进一步提高模型的执行效率。本节主要集中介绍模型小型化中需要注意的参数和指标，接着深入了解CNN经典的轻量化模型和Transformer结构的轻量化模型。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分类</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>内容</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>模型轻量化</p></td>
<td><p>01 推理参数了解</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1KW4y1G75J/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型小型化</p></td>
<td><p>02(上) CNN模型小型化</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Y84y1b7xj/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>模型小型化</p></td>
<td><p>02(下) CNN模型小型化</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1DK411k7qt/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型小型化</p></td>
<td><p>03 Transformer小型化</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV19d4y1V7ou/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id6">
<h3>模型压缩<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《模型压缩》模型压缩跟轻量化网络模型不同，压缩主要是对轻量化或者非轻量化模型执行剪枝、蒸馏、量化等压缩算法和手段，使得模型更加小、更加轻便、更加利于执行。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分类</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>内容</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>模型压缩</p></td>
<td><p>01 基本介绍</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1384y187tL/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型压缩</p></td>
<td><p>02 低比特量化原理</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1VD4y1n7AR/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>模型压缩</p></td>
<td><p>03 感知量化训练QAT</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1s8411w7b9/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型压缩</p></td>
<td><p>04
训练后量化PTQ与部署</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1HD4y1n7E1/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>模型压缩</p></td>
<td><p>05 模型剪枝原理</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1y34y1Z7KQ/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型压缩</p></td>
<td><p>06(上) 知识蒸馏原理</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1My4y197Tf/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>模型压缩</p></td>
<td><p>06(下) 知识蒸馏算法</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1vA411d7MF/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id7">
<h3>模型转换&amp;优化<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《模型转换&amp;优化》在这一节当中分为模型转换和模型优化，在整体架构图中属于离线模型转换模块。一方面，推理引擎需要把不同
AI
框架训练得到的模型进行转换；另外一方面需要对转换后的模型进行图优化等技术。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分类</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>内容</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>模型转换&amp;优化</p></td>
<td><p>01 基本介绍</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1724y1z7ep/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型转换模块</p></td>
<td><p>02 架构与文件格式</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV13P4y167sr/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>模型转换模块</p></td>
<td><p>03 自定义计算图IR</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1rx4y177R9/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>模型转换模块</p></td>
<td><p>04 模型转换流程</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV13341197zU/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>图优化模块</p></td>
<td><p>05 计算图优化策略</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1g84y1L7tF/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>图优化模块</p></td>
<td><p>06
常量折叠&amp;冗余节点消除</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1fA411r7hr/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>图优化模块</p></td>
<td><p>07 算子融合/替换/前移</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Qj411T7Ef/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>图优化模块</p></td>
<td><p>08
数据布局转换&amp;内存优化</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Ae4y1N7u7/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="kernel">
<h3>Kernel优化<a class="headerlink" href="#kernel" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《Kernel优化》在上层应用或者 AI
网络模型中，看到的是算子；但是在推理引擎实际执行的是具体的
Kernel，而推理引擎中 CNN 占据了主要是得执行时间，因此其 Kernel
优化尤为重要。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分类</p></th>
<th class="head"><p>名称</p></th>
<th class="head"><p>内容</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Kernel优化</p></td>
<td><p>01 Kernel优化架构</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Ze4y1c7Bb/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>Kernel优化</p></td>
<td><p>02 卷积操作原理</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1No4y1e7KX/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>Kernel优化</p></td>
<td><p>03 Im2Col算法</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1Ys4y1o7XW/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>Kernel优化</p></td>
<td><p>04 Winograd算法</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1vv4y1Y7sc/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>Kernel优化</p></td>
<td><p>05 QNNPack算法</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1ms4y1o7ki/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>Kernel优化</p></td>
<td><p>06 推理内存布局</p></td>
<td><p><a class="reference external" href="https://www.bilibili.com/video/BV1eX4y1X7mL/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>Kernel优化</p></td>
<td><p>07 nc4hw4内存排布</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Kernel优化</p></td>
<td><p>08 汇编与循环优化</p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">== 四、推理系统&amp;引擎 ==</a><ul>
<li><a class="reference internal" href="#id2">课程简介</a></li>
<li><a class="reference internal" href="#id3">课程细节</a><ul>
<li><a class="reference internal" href="#id4">推理系统</a></li>
<li><a class="reference internal" href="#id5">模型轻量化</a></li>
<li><a class="reference internal" href="#id6">模型压缩</a></li>
<li><a class="reference internal" href="#id7">模型转换&amp;优化</a></li>
<li><a class="reference internal" href="#kernel">Kernel优化</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../036CM_PyTorch/06.dispatch.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>5.6. Dispatch 机制</div>
         </div>
     </a>
     <a id="button-next" href="../041INF_Inference/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>1. 模型轻量化</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>