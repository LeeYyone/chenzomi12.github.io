<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>==== 二、AI芯片体系结构 &#8212; 人工智能系统（AISys） 0.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. AI 计算体系概述(视频)" href="../021HW_Foundation/README.html" />
    <link rel="prev" title="大模型的到来(待更)" href="../010system/06foundation.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active">==== 二、AI芯片体系结构</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/020Hardware/README.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/chenzomi12/DeepLearningSystem">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../010system/README.html">==== 一、AI系统概述</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../010system/01present.html">AI现状与大模型(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/02drive.html">AI发展驱动力(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/03architecture.html">AI系统全栈架构(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/04sample.html">AI系统样例(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/05principle.html">AI系统原则(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/06foundation.html">大模型的到来(待更)</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">==== 二、AI芯片体系结构</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021HW_Foundation/README.html">1. AI 计算体系概述(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/05.matrix.html">1.5. 核心计算之矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/06.bit_width.html">1.6. 计算之比特位宽</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022HW_ChipBase/README.html">2. AI 芯片基础(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/01.cpu_base.html">2.1. CPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/02.cpu_isa.html">2.2. CPU 指令集架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/03.cpu_data.html">2.3. CPU 计算本质</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/04.cpu_latency.html">2.4. CPU 计算时延</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/05.gpu.html">2.5. GPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/06.npu.html">2.6. NPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/07.future.html">2.7. 超异构计算</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023HW_GPUBase/README.html">3. GPU 原理详解(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/01.works.html">3.1. GPU工作原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/02.principle.html">3.2. 为什么 GPU 适用于 AI(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/03.base_concept.html">3.3. GPU架构与CUDA关系(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/04.fermi.html">3.4. GPU架构回顾第一篇(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/05.turing.html">3.5. GPU架构回顾第二篇(视频)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024HW_NVIDIA/README.html">4. NVIDIA GPU详解(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/01.basic_tc.html">4.1. TensorCore原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/02.history_tc.html">4.2. TensorCore架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/03.deep_tc.html">4.3. TensorCore剖析(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/04.basic_nvlink.html">4.4. 分布式通信与NVLink(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/05.deep_nvlink.html">4.5. NVLink原理剖析(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/06.deep_nvswitch.html">4.6. NVSwitch原理剖析(视频)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025HW_Abroad/README.html">5. 国外 AI 芯片架构(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/01.DOJO_Arch.html">5.1. 特斯拉DOJO架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/02.DOJO_Detail.html">5.2. 特斯拉DOJO Core原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/03.DOJO_System.html">5.3. 特斯拉DOJO存算系统(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/04.TPU_Introl.html">5.4. 谷歌TPU历史发展(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/05.TPU1.html">5.5. 谷歌TPUv1脉动阵列(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/06.TPU2.html">5.6. 谷歌TPUv2训练芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/07.TPU3.html">5.7. 谷歌TPUv3 POD形态</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/08.TPU4.html">5.8. 谷歌TPUv4三维互联</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/09.Future.html">5.9. 国外 AI 芯片思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026HW_Domestic/README.html">6. 国内 AI 芯片架构(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/01.BR100_System.html">6.1. 壁仞产品解读(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/02.BR100_Detail.html">6.2. 壁仞BR100架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/03.SUIYUAN_DTU.html">6.3. 燧原产品与DTU架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/04.cambricon_Product.html">6.4. 寒武纪产品解读(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/05.cambricon_Arch.html">6.5. 寒武纪MLU芯片架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/06.cambricon_Arch.html">6.6. 寒武纪MLU架构细节(视频)</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">==== 三、AI编译原理(更新中)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器(DOING)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 编译器基础介绍 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 传统编译器发展 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">==== 四、推理系统&amp;引擎</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Framework/README.html">==== 五、AI框架核心模块</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053FW_DataFlow/README.html">3. 计算图(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">==== 六、大模型训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">==== 附录(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">书写工具(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">书写规范(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">术语表(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">参考链接(DONE)</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="人工智能系统（AISys）"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../010system/README.html">==== 一、AI系统概述</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../010system/01present.html">AI现状与大模型(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/02drive.html">AI发展驱动力(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/03architecture.html">AI系统全栈架构(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/04sample.html">AI系统样例(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/05principle.html">AI系统原则(待更)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010system/06foundation.html">大模型的到来(待更)</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">==== 二、AI芯片体系结构</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../021HW_Foundation/README.html">1. AI 计算体系概述(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/01.introduction.html">1.1. 课程内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/02.arch_slim.html">1.2. AI计算模式(上)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/03.mobile_parallel.html">1.3. AI计算模式(下)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/04.metrics.html">1.4. 关键设计指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/05.matrix.html">1.5. 核心计算之矩阵乘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/06.bit_width.html">1.6. 计算之比特位宽</a></li>
<li class="toctree-l2"><a class="reference internal" href="../021HW_Foundation/07.summary.html">1.7. AI计算体系总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../022HW_ChipBase/README.html">2. AI 芯片基础(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/01.cpu_base.html">2.1. CPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/02.cpu_isa.html">2.2. CPU 指令集架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/03.cpu_data.html">2.3. CPU 计算本质</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/04.cpu_latency.html">2.4. CPU 计算时延</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/05.gpu.html">2.5. GPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/06.npu.html">2.6. NPU 基础</a></li>
<li class="toctree-l2"><a class="reference internal" href="../022HW_ChipBase/07.future.html">2.7. 超异构计算</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../023HW_GPUBase/README.html">3. GPU 原理详解(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/01.works.html">3.1. GPU工作原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/02.principle.html">3.2. 为什么 GPU 适用于 AI(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/03.base_concept.html">3.3. GPU架构与CUDA关系(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/04.fermi.html">3.4. GPU架构回顾第一篇(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../023HW_GPUBase/05.turing.html">3.5. GPU架构回顾第二篇(视频)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../024HW_NVIDIA/README.html">4. NVIDIA GPU详解(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/01.basic_tc.html">4.1. TensorCore原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/02.history_tc.html">4.2. TensorCore架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/03.deep_tc.html">4.3. TensorCore剖析(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/04.basic_nvlink.html">4.4. 分布式通信与NVLink(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/05.deep_nvlink.html">4.5. NVLink原理剖析(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../024HW_NVIDIA/06.deep_nvswitch.html">4.6. NVSwitch原理剖析(视频)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../025HW_Abroad/README.html">5. 国外 AI 芯片架构(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/01.DOJO_Arch.html">5.1. 特斯拉DOJO架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/02.DOJO_Detail.html">5.2. 特斯拉DOJO Core原理(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/03.DOJO_System.html">5.3. 特斯拉DOJO存算系统(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/04.TPU_Introl.html">5.4. 谷歌TPU历史发展(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/05.TPU1.html">5.5. 谷歌TPUv1脉动阵列(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/06.TPU2.html">5.6. 谷歌TPUv2训练芯片</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/07.TPU3.html">5.7. 谷歌TPUv3 POD形态</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/08.TPU4.html">5.8. 谷歌TPUv4三维互联</a></li>
<li class="toctree-l2"><a class="reference internal" href="../025HW_Abroad/09.Future.html">5.9. 国外 AI 芯片思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../026HW_Domestic/README.html">6. 国内 AI 芯片架构(视频)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/01.BR100_System.html">6.1. 壁仞产品解读(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/02.BR100_Detail.html">6.2. 壁仞BR100架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/03.SUIYUAN_DTU.html">6.3. 燧原产品与DTU架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/04.cambricon_Product.html">6.4. 寒武纪产品解读(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/05.cambricon_Arch.html">6.5. 寒武纪MLU芯片架构(视频)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../026HW_Domestic/06.cambricon_Arch.html">6.6. 寒武纪MLU架构细节(视频)</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../030Compiler/README.html">==== 三、AI编译原理(更新中)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../031CM_Tradition/README.html">1. 传统编译器(DOING)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/01.introduction.html">1.1. 编译器基础介绍 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/02.history.html">1.2. 传统编译器发展 OK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/03.gcc.html">1.3. GCC编译过程和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/04.llvm.html">1.4. LLVM架构设计和原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/05.llvm_detail01.html">1.5. LLVM IR详解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/06.llvm_detail02.html">1.6. LLVM前端和优化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../031CM_Tradition/07.llvm_detail03.html">1.7. LLVM后端代码生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../032CM_AICompiler/README.html">2. AI 编译器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/01.appear.html">2.1. 为什么需要AI编译器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/02.stage.html">2.2. AI编译器的发展阶段</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/03.architecture.html">2.3. AI编译器的通用架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../032CM_AICompiler/04.future.html">2.4. AI编译器挑战与思考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../033CM_Frontend/README.html">3. 前端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/01.introduction.html">3.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/02.graph_ir.html">3.2. 图算 IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../033CM_Frontend/03.op_fusion.html">3.3. 算子融合</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../034CM_Backend/README.html">4. 后端优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/01.introduction.html">4.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/02.ops_compute.html">4.2. 算子的计算与调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/03.optimization.html">4.3. 算子手工优化方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/04.loop_opt.html">4.4. 算子循环优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/05.other_opt.html">4.5. 指令和内存优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../034CM_Backend/06.auto_tuning.html">4.6. Auto-Tuning原理</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../036CM_PyTorch/README.html">5. PyTorch2.0 图模式</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/01.introduction.html">5.1. PyTorch2.0 特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/02.torchscript.html">5.2. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/03.torchfx_lazy.html">5.3. FX 与 LazyTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/04.torchdynamo.html">5.4. TorchDynamo 获取图</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/05.aotatuograd.html">5.5. AOTAutograd 原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../036CM_PyTorch/06.dispatch.html">5.6. Dispatch 机制</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../040Inference/README.html">==== 四、推理系统&amp;引擎</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../041INF_Inference/README.html">1. 推理系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/01.introduction.html">1.1. 内容介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/02.constraints.html">1.2. 推理系统介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/03.workflow.html">1.3. 推理流程全景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/04.system.html">1.4. 推理系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/05.inference.html">1.5. 推理引擎架构（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../041INF_Inference/06.architecture.html">1.6. 推理引擎架构（下）</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../042INF_Mobilenet/README.html">2. 模型轻量化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/01.introduction.html">2.1. 推理参数了解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/02.cnn.html">2.2. CNN模型小型化（上）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/03.cnn.html">2.3. CNN模型小型化（下）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../042INF_Mobilenet/04.transformer.html">2.4. Transformer小型化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../043INF_Slim/README.html">3. 模型压缩</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/02.quant.html">3.2. 低比特量化原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/03.qat.html">3.3. 感知量化训练QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/04.ptq.html">3.4. 训练后量化PTQ与部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/05.pruning.html">3.5. 模型剪枝原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/06.distillation.html">3.6. 知识蒸馏原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../043INF_Slim/07.distillation.html">3.7. 知识蒸馏算法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../044INF_Converter/README.html">4. 模型转换&amp;优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/01.introduction.html">4.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/02.converter_princ.html">4.2. 架构与文件格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/03.converter_ir.html">4.3. 自定义计算图IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/04.converter_detail.html">4.4. 模型转换流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/05.optimizer.html">4.5. 计算图优化策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/06.basic.html">4.6. 常量折叠&amp;冗余节点消除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../044INF_Converter/07.extend.html">4.7. 算子融合/替换/前移</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../045INF_Kernel/README.html">5. Kernel优化</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/01.introduction.html">5.1. Kernel优化架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/02.conv.html">5.2. 卷积操作原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/03.im2col.html">5.3. Im2Col算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/04.winograd.html">5.4. Winograd算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/05.qnnpack.html">5.5. QNNPack算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/06.memory.html">5.6. 推理内存布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/07.nc4hw4.html">5.7. nc4hw4内存排布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../045INF_Kernel/08.others.html">5.8. 汇编与循环优化</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../050Framework/README.html">==== 五、AI框架核心模块</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../051FW_Foundation/README.html">1. AI框架基础(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/01.introduction.html">1.1. 本章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/02.fundamentals.html">1.2. AI框架作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/03.history.html">1.3. AI框架之争</a></li>
<li class="toctree-l2"><a class="reference internal" href="../051FW_Foundation/04.programing.html">1.4. 框架编程范式</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../052FW_AutoDiff/README.html">2. 自动微分(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/01.introduction.html">2.1. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/02.base_concept.html">2.2. 什么是微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/03.grad_mode.html">2.3. 微分计算模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/04.implement.html">2.4. 微分实现方式</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/05.forward_mode.html">2.5. 动手实现自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/06.reversed_mode.html">2.6. 动手实现PyTorch微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../052FW_AutoDiff/07.challenge.html">2.7. 自动微分的挑战&amp;未来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../053FW_DataFlow/README.html">3. 计算图(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/02.computegraph.html">3.2. 计算图原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/03.atuodiff.html">3.3. 计算图与自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/04.dispatch.html">3.4. 计算图的调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/05.control_flow.html">3.5. 计算图的控制流实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/06.static_graph.html">3.6. 动态图与静态图转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../053FW_DataFlow/07.future.html">3.7. 计算图的挑战&amp;未来</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../060Foundation/README.html">==== 六、大模型训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../061FW_AICluster/README.html">1. 分布式集群</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/01.introduction.html">1.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/02.architecture.html">1.2. AI集群服务器架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/03.communication.html">1.3. AI集群软硬件通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/04.primitive.html">1.4. 集合通信原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../061FW_AICluster/05.system.html">1.5. 分布式功能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../062FW_AIAlgo/README.html">2. 分布式算法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/01.challenge.html">2.1. 大模型训练挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/02.algorithm_arch.html">2.2. 大模型算法结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../062FW_AIAlgo/03.algorithm_sota.html">2.3. 亿级规模大模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../063FW_Parallel/README.html">3. 分布式并行</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/01.introduction.html">3.1. 基本介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/02.data_parallel.html">3.2. 数据并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/03.tensor_parallel.html">3.3. 张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/04.mindspore_parallel.html">3.4. MindSpore张量并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/05.pipeline_parallel.html">3.5. 流水并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/06.hybrid_parallel.html">3.6. 混合并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../063FW_Parallel/07.summary.html">3.7. 分布式训练总结</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../000Others/README.html">==== 附录(DONE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../000Others/instruments.html">书写工具(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/criterion.html">书写规范(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/glossary.html">术语表(DONE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../000Others/inference.html">参考链接(DONE)</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <!--Copyright © ZOMI 适用于[License](https://github.com/chenzomi12/DeepLearningSystem)版权许可--><div class="section" id="ai">
<h1>==== 二、AI芯片体系结构<a class="headerlink" href="#ai" title="Permalink to this heading">¶</a></h1>
<p>AI硬件体系结构主要是指AI芯片，这里就很硬核了，从芯片的基础到AI芯片的范围都会涉及，芯片设计需要考虑上面AI框架的前端、后端编译，而不是停留在天天喊着吊打英伟达，被现实打趴。</p>
<blockquote>
<div><p>欢迎大家使用的过程中发现bug或者勘误直接提交PR到开源社区哦！</p>
</div></blockquote>
<blockquote>
<div><p>请大家尊重开源和ZOMI的努力，引用PPT的内容请规范转载标明出处哦！</p>
</div></blockquote>
<div class="section" id="id1">
<h2>课程简介<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>《AI
计算体系概述》</strong>：深入深度学习计算模式，从而理解“计算”需要什么。通过AI芯片关键指标，了解AI芯片要更好的支持“计算”，需要关注那些重点工作。最后通过深度学习的计算核心“矩阵乘”来看对“计算”的实际需求和情况，为了提升计算性能、降低功耗和满足训练推理不同场景应用，对“计算”引入
TF32/BF16 等复杂多样的比特位宽。</p></li>
<li><p><strong>《AI
芯片基础》</strong>：简单从CPU开始看通用逻辑架构（冯诺依曼架构）开始，通过打开计算的本质（数据与时延）从而引出对于并行计算GPU作用和解决的业务场景，到目前最火的AI芯片NPU。最后迈入超异构并行CPU、GPU、NPU并存的计算系统架构黄金十年。</p></li>
<li><p><strong>《GPU
原理详解》</strong>：主要是深入地讲解GPU的工作原理，其最重要的指标是计算吞吐和存储和传输带宽，并对英伟达的GPU的十年5代架构进行梳理。此外，《NVIDIA
GPU详解》英伟达架构里面专门为AI而生的 Tensor Core 和 NVLink
对AI加速尤为重要，因此重点对 Tensor Core 和 NVLink
进行深入剖析其发展、演进和架构。</p></li>
<li><p><strong>《国外AI芯片》</strong>：深入地剖析国外 Google TPU 和特斯拉 DOJO 相关 AI
芯片的架构，以TPU为主主要使用了数据流（Data
FLow）的方式的脉动阵列来加速矩阵的运算，而特斯拉则使用了近存计算（Near
Memory）两种不同的产品形态。</p></li>
<li><p><strong>《国内AI芯片》</strong>：深入地解读国内 AI
初创芯片厂商如国内第一AI芯片上市公司寒武纪、国内造GPU声势最大的壁仞科技、腾讯重头的燧原科技等科技公司的
AI 芯片架构。</p></li>
</ul>
<p>希望这个系列能够给大家、朋友们带来一些些帮助，也希望自己能够继续坚持完成所有内容哈！</p>
</div>
<div class="section" id="id2">
<h2>课程细节<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<blockquote>
<div><p><em>建议优先下载或者使用PDF版本，PPT版本会因为字体缺失等原因导致版本很丑哦~</em></p>
</div></blockquote>
<div class="section" id="id3">
<h3>AI 计算体系<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《AI
计算体系》深入深度学习计算模式，从而理解“计算”需要什么。通过AI芯片关键指标，了解AI芯片要更好的支持“计算”，需要关注那些重点工作。最后通过深度学习的计算核心“矩阵乘”来看对“计算”的实际需求和情况，为了提升计算性能、降低功耗和满足训练推理不同场景应用，对“计算”引入
TF32/BF16 等复杂多样的比特位宽。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>大纲</p></th>
<th class="head"><p>小节</p></th>
<th class="head"><p>链接</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AI 计算体系</p></td>
<td><p>01 课程内容</p></td>
<td><p><a class="reference external" href="./021HW_Foundation/01.introduction.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1DX4y1D7PC/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 计算体系</p></td>
<td><p>02 AI计算模式(上)</p></td>
<td><p><a href="#id13"><span class="problematic" id="id14">`slide &lt;
./021HW_Foundation/02
.constraints.pdf&gt;`__</span></a>,
<a class="reference external" href="https://www.bilibili.com/video/BV17x4y1T7Cn/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>AI 计算体系</p></td>
<td><p>03 AI计算模式(下)</p></td>
<td><p><a class="reference external" href="./021HW_Foundation/03.mobile_parallel.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1754y1M78X/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 计算体系</p></td>
<td><p>04 关键设计指标</p></td>
<td><p><a class="reference external" href="./021HW_Foundation/04.metrics.pdf">sli
de</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1qL411o7S9/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>AI 计算体系</p></td>
<td><p>05 核心计算：矩阵乘</p></td>
<td><p><a class="reference external" href="./021HW_Foundation/05.matrix.pdf">sl
ide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1ak4y1h7mp/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 计算体系</p></td>
<td><p>06 数据单位：bits</p></td>
<td><dl class="simple">
<dt><a href="#id4"><span class="problematic" id="id5">`</span></a>slide</dt><dd><p>&lt;./021HW_Foundation/</p>
</dd>
</dl>
<p>06.bit_width.pdf&gt;`__,
<a class="reference external" href="https://www.bilibili.com/video/BV1WT411k724/">video</a></p>
</td>
</tr>
<tr class="row-even"><td><p>AI 计算体系</p></td>
<td><p>07 AI计算体系总结</p></td>
<td><p><a class="reference external" href="./021HW_Foundation/07.summary.pdf">sli
de</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1j54y1T7ii/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id6">
<h3>AI 芯片基础<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《AI
芯片基础》简单从CPU开始看通用逻辑架构（冯诺依曼架构）开始，通过打开计算的本质（数据与时延）从而引出对于并行计算GPU作用和解决的业务场景，到目前最火的AI芯片NPU。最后迈入超异构并行CPU、GPU、NPU并存的计算系统架构黄金十年。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>大纲</p></th>
<th class="head"><p>小节</p></th>
<th class="head"><p>链接</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AI 芯片基础</p></td>
<td><p>01 CPU 基础</p></td>
<td><p><a class="reference external" href="./022HW_ChipBase/01.cpu_base.pdf">sl
ide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1tv4y1V72f/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 芯片基础</p></td>
<td><p>02 CPU 指令集架构</p></td>
<td><p><a class="reference external" href="./022HW_ChipBase/02.cpu_isa.pdf">s
lide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1ro4y1W7xN/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>AI 芯片基础</p></td>
<td><p>03 CPU 计算本质</p></td>
<td><p><a class="reference external" href="./022HW_ChipBase/03.cpu_data.pdf">sl
ide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV17X4y1k7eF/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 芯片基础</p></td>
<td><p>04 CPU 计算时延</p></td>
<td><dl class="simple">
<dt><a href="#id7"><span class="problematic" id="id8">`</span></a>slide</dt><dd><p>&lt;./022HW_ChipBase/04</p>
</dd>
</dl>
<p>.cpu_latency.pdf&gt;`__,
<a class="reference external" href="https://www.bilibili.com/video/BV1Qk4y1i7GT/">video</a></p>
</td>
</tr>
<tr class="row-even"><td><p>AI 芯片基础</p></td>
<td><p>05 GPU 基础</p></td>
<td><p><a class="reference external" href="./022HW_ChipBase/05.gpu.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1sM411T72Q/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>AI 芯片基础</p></td>
<td><p>06 NPU 基础</p></td>
<td><p><a class="reference external" href="./022HW_ChipBase/06.npu.pptx">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1Rk4y1e77n/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>AI 芯片基础</p></td>
<td><p>07 超异构计算</p></td>
<td><p>`
slide &lt;./022HW_ChipBa
se/07.future.pdf&gt;`__,
<a class="reference external" href="https://www.bilibili.com/video/BV1YM4y117VK">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="gpu">
<h3>GPU 原理详解<a class="headerlink" href="#gpu" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>《GPU
原理详解》主要是深入地讲解GPU的工作原理，其最重要的指标是计算吞吐和存储和传输带宽，并对英伟达的GPU的十年5代架构进行梳理。英伟达架构里面专门为AI而生的
Tensor Core 和 NVLink 对AI加速尤为重要，因此重点对 Tensor Core 和
NVLink 进行深入剖析其发展、演进和架构。</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>大纲</p></th>
<th class="head"><p>小节</p></th>
<th class="head"><p>链接</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GPU 原理详解</p></td>
<td><p>01 GPU工作原理</p></td>
<td><p><a class="reference external" href="./03_GPUBase/01.works.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1bm4y1m7Ki/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>GPU 原理详解</p></td>
<td><p>02 GPU适用于AI</p></td>
<td><p><a class="reference external" href="./03_GPUBase/02.principle.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1Ms4y1N7RL/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>GPU 原理详解</p></td>
<td><p>03 GPU架构与CUDA关系</p></td>
<td><p><a class="reference external" href="./03_GPUBase/03.base_concept.pdf">sl
ide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1Kk4y1Y7op/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>GPU 原理详解</p></td>
<td><p>04 GPU架构回顾第一篇</p></td>
<td><p><a class="reference external" href="./03_GPUBase/04.fermi.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1x24y1F7kY/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>GPU 原理详解</p></td>
<td><p>05 GPU架构回顾第二篇</p></td>
<td><p><a class="reference external" href="./03_GPUBase/05.turing.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1mm4y1C7fg/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>–</p></td>
<td><p>–</p></td>
<td><p>–</p></td>
</tr>
<tr class="row-even"><td><p>NVIDIA GPU详解</p></td>
<td><p>01 TensorCore原理(上)</p></td>
<td><p>`
slide &lt;./04_GPUDetail
/01.basic_tc.pdf&gt;`__,
<a class="reference external" href="https://www.bilibili.com/video/BV1aL411a71w/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>NVIDIA GPU详解</p></td>
<td><p>02 TensorCore架构(中)</p></td>
<td><p><a class="reference external" href="./04_GPUDetail/02.history_tc.pdf">sl
ide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1pL41187FH/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>NVIDIA GPU详解</p></td>
<td><p>03 TensorCore剖析(下)</p></td>
<td><p><a class="reference external" href="./04_GPUDetail/03.deep_tc.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1oh4y1J7B4/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>NVIDIA GPU详解</p></td>
<td><p>04 分布式通信与NVLink</p></td>
<td><p><a class="reference external" href="./04_GPUDetail/04.basic_nvlink.pdf">slid
e</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1cV4y1r7Rz/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>NVIDIA GPU详解</p></td>
<td><p>05 NVLink原理剖析</p></td>
<td><p><a class="reference external" href="./04_GPUDetail/05.deep_nvlink.pdf">sli
de</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1uP411X7Dr/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>NVIDIA GPU详解</p></td>
<td><p>05 NVSwitch原理剖析</p></td>
<td><dl class="simple">
<dt><a href="#id9"><span class="problematic" id="id10">`</span></a>slide</dt><dd><p>&lt;./04_GPUDetail/06.d</p>
</dd>
</dl>
<p>eep_nvswitch.pdf&gt;`__,
<a class="reference external" href="https://www.bilibili.com/video/BV1uM4y1n7qd/">video</a></p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id11">
<h3>国外AI芯片<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h3>
<p>更新中ING…</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>大纲</p></th>
<th class="head"><p>小节</p></th>
<th class="head"><p>链接</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>国外AI芯片</p></td>
<td><p>01 特斯拉DOJO架构</p></td>
<td><p><a class="reference external" href="./05_NPU/01.DOJO_Arch.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1Ro4y1M7n8/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>国外AI芯片</p></td>
<td><p>02 特斯拉DOJO
Core原理</p></td>
<td><p><a class="reference external" href="./05_NPU/02.DOJO_Detail.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV17o4y1N7Yn/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>国外AI芯片</p></td>
<td><p>03 特斯拉DOJO存算系统</p></td>
<td><p><a class="reference external" href="./05_NPU/03.DOJO_System.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1Ez4y1e7zo/">video</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id12">
<h3>国内AI芯片<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h3>
<p>更新中ING…</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>大纲</p></th>
<th class="head"><p>小节</p></th>
<th class="head"><p>链接</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>国内AI芯片</p></td>
<td><p>01 壁仞产品解读</p></td>
<td><p><a class="reference external" href="./05_NPU/04.BR100_System.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1QW4y1S75Y/">video</a></p></td>
</tr>
<tr class="row-odd"><td><p>国内AI芯片</p></td>
<td><p>02 壁仞BR100架构</p></td>
<td><p><a class="reference external" href="./05_NPU/05.BR100_Detail.pdf">slide</a>,
<a class="reference external" href="https://www.bilibili.com/video/BV1G14y1275T/">video</a></p></td>
</tr>
<tr class="row-even"><td><p>国内AI芯片</p></td>
<td><p>03 燧原产品与DTU架构</p></td>
<td><p><a class="reference external" href="./05_NPU/06.SUIYUAN_DTU.pdf">slide</a>,
<a href="#id13"><span class="problematic" id="id15">`video &lt;&gt;`__</span></a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">==== 二、AI芯片体系结构</a><ul>
<li><a class="reference internal" href="#id1">课程简介</a></li>
<li><a class="reference internal" href="#id2">课程细节</a><ul>
<li><a class="reference internal" href="#id3">AI 计算体系</a></li>
<li><a class="reference internal" href="#id6">AI 芯片基础</a></li>
<li><a class="reference internal" href="#gpu">GPU 原理详解</a></li>
<li><a class="reference internal" href="#id11">国外AI芯片</a></li>
<li><a class="reference internal" href="#id12">国内AI芯片</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../010system/06foundation.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>大模型的到来(待更)</div>
         </div>
     </a>
     <a id="button-next" href="../021HW_Foundation/README.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>1. AI 计算体系概述(视频)</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>